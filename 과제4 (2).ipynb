{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제1  \n",
    "\n",
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog\n",
      "dog pig\n",
      "ham bird\n",
      "pig ham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"s.txt\")\n",
    "a = f.readlines()\n",
    "a[-1] = a[-1] + '\\n'\n",
    "a.sort()\n",
    "f.close()\n",
    "\n",
    "f = open(\"s1.txt\",\"w\")\n",
    "f.writelines(a)\n",
    "f.close()\n",
    "f = open(\"s1.txt\")\n",
    "print(f.read())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. f로 pwd 상에 있는 s.txt 텍스트파일을 디폴트(읽기모드)로 open한다.\n",
    "2. 모든 문자열을 라인(\\n)으로 구분하여 가져와 a에 리스트형식으로 저장한다.\n",
    "3. 맨 마지막 라인의 마지막에는 개행문자가 없으므로 추가해준다.\n",
    "4. sort() 메소드로 a를 첫번째 문자를 기준으로 정렬한다.\n",
    "5. 파일을 닫고(close) 다시 쓰기전용 모드로 open한다.\n",
    "6. 라인단위로 파일에 문자열들을 저장 후 파일을 닫는다.\n",
    "7. 다시 파일을 열어 read() 메소드로 문자열들을 읽어온 후 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog\n",
      "ham bird\n",
      "pig ham\n",
      "dog pig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sortList(a) :\n",
    "    return a[1]\n",
    "\n",
    "f = open(\"s.txt\")\n",
    "a = f.readlines()\n",
    "a[-1] = a[-1] + '\\n'\n",
    "a.sort(key = sortList)\n",
    "f.close()\n",
    "\n",
    "f = open(\"s2.txt\",\"w\")\n",
    "f.writelines(a)\n",
    "f.close()\n",
    "f = open(\"s2.txt\")\n",
    "print(f.read())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이번에는 2번째 단어를 기준으로 정렬해야하므로 그냥 sort()만 사용하면 안된다.  \n",
    "  그러므로 문자열을 인자로 받아 1번째 인자값을 반환하도록 하는 sortList 함수를 sort의 key값으로 지정한다.\n",
    "2. 그외 나머지는 1번과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pig ham cat \n",
      "dog ham bird \n",
      "dog pig \n"
     ]
    }
   ],
   "source": [
    "f = open(\"s.txt\")\n",
    "a = f.readlines()\n",
    "b = []\n",
    "b = [x.split() for x in a]\n",
    "c = [k for x in b for k in x]\n",
    "f.close()\n",
    "\n",
    "f = open(\"s3.txt\",\"w\")\n",
    "i=0\n",
    "for x in c:\n",
    "    f.write(x)\n",
    "    f.write(\" \")\n",
    "    i+=1\n",
    "    if i%3==0:\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"s3.txt\")\n",
    "print(f.read())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. f로 s.txt를 열고 a에 라인마다 문자열을 리스트로 저장한다.\n",
    "2. b에 a리스트 각각의 문자열을 split메소드를 이용해 단어마다 b에 저장한다.\n",
    "3. 모든 단어들을 하나의 c리스트에 넣는다.  \n",
    "   => ['pig', 'ham', 'cat', 'dog', 'ham', 'bird', 'dog', 'pig']\n",
    "4. 쓰기모드로 s3.txt파일을 연다.\n",
    "5. c리스트의 원소들을 공백(' ')으로 구부하여 하나하나씩 넣으면서 3개마다 개행문자  \n",
    "   ('\\n')를 넣어준다. 그 후 s3.txt를 읽기모드로 열어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to Our Service !\n",
      "    1. Sign up\n",
      "    2. Sign in\n",
      "    3. Quit \n",
      "1\n",
      "ID : pyj99\n",
      "PassWord : 123456\n",
      "Name : 박영준\n",
      "School : 한기대\n",
      "\n",
      "\n",
      "Welcome to Our Service !\n",
      "    1. Sign up\n",
      "    2. Sign in\n",
      "    3. Quit \n",
      "1\n",
      "ID : pyj99\n",
      "Sorry, the entered ID is already used.\n",
      "ID : kyj1010\n",
      "PassWord : 1010\n",
      "Name : 김용준\n",
      "School : 서울대\n",
      "\n",
      "\n",
      "Welcome to Our Service !\n",
      "    1. Sign up\n",
      "    2. Sign in\n",
      "    3. Quit \n",
      "2\n",
      "Press ID : pyj88\n",
      "Sorry, you are not a registered member.\n",
      "Press ID : pyj99\n",
      "Press PassWord : 123\n",
      "Sorry, the entered password is not correct.\n",
      "Press PassWord : 123456\n",
      "\n",
      "Hello pyj99 !\n",
      "\n",
      "-----------------------------------------------사용자 정보-----------------------------------------------\n",
      "\n",
      "[pyj99]: [8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92], [박영준], [한기대]\n",
      "[kyj1010]: [7a5df5ffa0dec2228d90b8d0a0f1b0767b748b0a41314c123075b8289e4e053f], [김용준], [서울대]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: sha256 -*-\n",
    "import hashlib,string\n",
    "cnt =0 #저장된 계정갯수\n",
    "\n",
    "\n",
    "def encryption(password): #암호화 함수\n",
    "    password_plain = hashlib.sha256()\n",
    "    password_encrypted = password_plain.update(password.encode('utf-8'))\n",
    "    password_encrypted = password_plain.hexdigest()\n",
    "    password = str(password_encrypted)\n",
    "    return password\n",
    "    \n",
    "while(True):\n",
    "    print(\"\"\"\\n\\nWelcome to Our Service !\n",
    "    1. Sign up\n",
    "    2. Sign in\n",
    "    3. Quit \"\"\")\n",
    "    n = int(input())\n",
    "    if n==1 :\n",
    "        f = open(\"access.txt\",\"a+\")\n",
    "        info = [] #계정정보(form, 4가지)\n",
    "        form = ['ID : ','PassWord : ','Name : ','School : ']\n",
    "        f.seek(0)\n",
    "\n",
    "        for k in form :\n",
    "            a = input(k)\n",
    "            if k=='ID : ' and cnt >0 :\n",
    "                q = f.readlines()\n",
    "\n",
    "                b = []\n",
    "                for x in q:\n",
    "                    b.append(x.split(' '))\n",
    "\n",
    "                c = []\n",
    "                for x in b :\n",
    "                    c.append(x[0])\n",
    "\n",
    "                d = []\n",
    "                for x in c :\n",
    "                    d.append(str(x).strip(string.punctuation))\n",
    "                while '' in d:\n",
    "                    d.remove('')\n",
    "\n",
    "                #c = [x for x in b if (':' in x) == True]\n",
    "                #d = [x.strip(':') for x in c]\n",
    "                if a in d:\n",
    "                    while(True):\n",
    "                        print('Sorry, the entered ID is already used.')\n",
    "                        a = input(k)\n",
    "                        if(a not in d):\n",
    "                            break        \n",
    "\n",
    "            if k=='PassWord : ':\n",
    "                #hasher = hashlib.sha256()\n",
    "                #password_plain = hashlib.sha256()\n",
    "                #password_encrypted = password_plain.update(a.encode('utf-8'))\n",
    "                #password_encrypted = password_plain.hexdigest()\n",
    "                a = encryption(a)\n",
    "            info.append(a)\n",
    "        for i in range(len(info)):\n",
    "            if i==0:\n",
    "                info[i] = '[' + info[i] + ']'\n",
    "                f.write(info[i])\n",
    "                f.write(\": \")\n",
    "            elif i<len(info)-1:\n",
    "                info[i] = '[' + info[i] + ']'\n",
    "                f.write(info[i])\n",
    "                f.write(\", \")\n",
    "            else :\n",
    "                info[i] = '[' + info[i] + ']'\n",
    "                f.write(info[i])\n",
    "                f.write(\"\\n\")\n",
    "        cnt+=1        \n",
    "        f.close()\n",
    "\n",
    "    elif n==2 :\n",
    "        f = open(\"access.txt\",\"r\")\n",
    "        id = input(\"Press ID : \")\n",
    "\n",
    "        f.seek(0)\n",
    "        q = f.readlines()      \n",
    "        b = []\n",
    "        for x in q:\n",
    "            b.append(x.split(' '))\n",
    "\n",
    "        c = []\n",
    "        for x in b :\n",
    "            c.append(x[0])\n",
    "\n",
    "        d = []\n",
    "        for x in c :\n",
    "            d.append(str(x).strip(string.punctuation))\n",
    "        \n",
    "\n",
    "        #c = [x for x in b if (':' in x) == True]\n",
    "        #d = [x.strip(':') for x in c]\n",
    "        \n",
    "        if id not in d:\n",
    "            while(True):\n",
    "                print('Sorry, you are not a registered member.')\n",
    "                id = input(\"Press ID : \")\n",
    "                if(id in d):\n",
    "                    id_index = d.index(id)\n",
    "                    break\n",
    "        else :\n",
    "            id_index = d.index(id)\n",
    "        password = input(\"Press PassWord : \")\n",
    "        password = encryption(password)\n",
    "        c = []\n",
    "        for x in b :\n",
    "            c.append(x[1])\n",
    "\n",
    "        d = []\n",
    "        for x in c :\n",
    "            d.append(str(x).strip(string.punctuation))\n",
    "\n",
    "        if password != d[id_index]:\n",
    "            while(True):\n",
    "                print('Sorry, the entered password is not correct.')\n",
    "                password = input(\"Press PassWord : \")\n",
    "                password = encryption(password)\n",
    "                if(password == d[id_index]):\n",
    "                    break\n",
    "        print()\n",
    "        print(\"Hello\", id, \"!\\n\")\n",
    "        break\n",
    "    elif n == 3 :\n",
    "        print(\"프로그램을 종료합니다. \")\n",
    "        break\n",
    "\n",
    "f = open(\"access.txt\")\n",
    "print('사용자 정보'.center(100,'-'))\n",
    "print()\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체적인 구조  \n",
    "\n",
    "- while(True)\n",
    "    - n이 1일 때(Sign up)\n",
    "        - 'a+' 타입으로 access.txt 파일객체 생성(f), a+는 쓰기(append), 읽기 모두가능\n",
    "        - info는 1인당 정보를 저장하는 리스트\n",
    "        - form은 ~를 입력하시오. 에서 ~.\n",
    "        - 파일이 끝나면 파일형식이 a이므로 파일포인터를 처음으로 돌리기위해 f.seek(0) 사용\n",
    "        - cnt는 현재 파일에 저장되어있는 계정정보 개수\n",
    "        - 입력받는것이 ID 이고 cnt가 0보다 클 때(기존 계정정보가 있을 때)-----\n",
    "          - q에 파일의 모든 라인을 받아옴  \n",
    "            각 라인을 공백으로 나누고 b리스트에 저장\n",
    "            b 각원소의 0번째는 ID. 이들을 c리스트에 저장  \n",
    "            [ID] 형식이므로 strip으로 string의 punctuation을 stip으로 모두 제거 후 d에 저장\n",
    "        - 이제 저장되어있는 모든 ID가 d리스트에 저장되어있으므로 현재 입력받는 아이디와 리스트d를 비교해 기존에 있으면 없을때까지 계속받고 기존에 없으면 패스워드 입력으로 넘어간다.\n",
    "        - 입력받는것이 PassWord일 때-----\n",
    "            - import한 hashlib의 sha256 이라는 해시알고리즘을 이용해 PassWord를 암호화한다. - ( 비밀번호를 인자로 받아 암호화시켜주는 encryption 함수를 따로 구현)\n",
    "            password_plain은 sha256으로 암호화된 것.\n",
    "            입력받은 비밀번호를 utf-8모드로 인코딩된 것을 password_encrypted에 update.\n",
    "            password_plain을 16진수화해서 다시 encrypted에 저장.\n",
    "            password를 반환\n",
    "            입력받은 a(PassWord) 는 기존에서 str형태로 암호화되어 다시 저장된다.\n",
    "        - [이름], [학교]는 건드릴 부분이 없으므로 이로써 4가지의 계정정보를 info리스트에 저장한다.\n",
    "        - 바로 밑 부분의 for문은 각각의 정보들에 부가적으로 붙는 특수문자들에대한 처리부분이다.\n",
    "        - 마지막으로 cnt(저장된 계정 개수)를 증가시켜준다.  \n",
    "        \n",
    "  - n이 2일 때(Sign in)\n",
    "      - 'r' 타입으로 access.txt 파일객체 생성(f)\n",
    "      - 모든 라인을 받아와 모든 ID를 d리스트에 저장한다.( n이 1일 때와 동일)\n",
    "      - ID가 d에 없으면 ----\n",
    "          - d에 존재하는 ID(등록된 아이디)가 나올때까지 ID를 다시 입력받음.\n",
    "          - 해당 아이디에 맞는 비밀번호여야 하므로 해당아이디의 index를 구함(id_index = (d.index(id))\n",
    "      - ID가 d에 있으면 ----\n",
    "          - 해당 아이디의 인덱스(id_index)를 구함\n",
    "      - 비밀번호도 마찬가지로 리스트d에 특수문자를 제외한 암호화된 비밀번호를 저장\n",
    "      - id인덱스에 해당하는 비밀번호가 입력한 비밀번호와 다를 때 ----\n",
    "           - 아이디에 해당하는 비밀번호와 맞을때까지 비밀번호를 다시 입력받음\n",
    "           - 맞으면 빠져나온다. (break)\n",
    "  - n이 3일 때(Quit)\n",
    "    -  break\n",
    "  \n",
    "        \n",
    "            \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.2', '0.8', '1.4']\n"
     ]
    }
   ],
   "source": [
    "def frange(stop, start=0.0,  step=0.1) :\n",
    "    a =[]\n",
    "    while start <= stop :\n",
    "        a.append(\"%.1f\"%start)\n",
    "        start += step\n",
    "    print(a)\n",
    "frange(1.6,0.2,0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. frange 함수는 stop, start, step을 인자로 받는다. 이 때 start와 step은 default값이 있으므로 default값이 없는 stop 뒤에 위치해야 한다.\n",
    "2. 빈 리스트 a를 선언해주고 start가 stop보다 작거나 같을 때 까지 start의 소수점 첫째자리까지 a에 저장하고 start에 step을 더해준다. \n",
    "3. a를 출력한다  \n",
    "\n",
    "*부동소수점 오차로 인해 값이 0.30000000000004 이런식으로 나와서 포매팅 방식을 이용해 소수점 첫째자리까지 출력했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "def sum(*a):\n",
    "    sum =0\n",
    "    for x in a:\n",
    "        sum += x\n",
    "    print(sum)\n",
    "sum(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가변인수 a는 튜플형식이기 때문에 for~in 문으로 각각의 원소에 접근할 수 있다.\n",
    "따라서 sum을 0으로 초기화해주고 가변인수 a 각각의 원소인 x를 sum에 더해준 후 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as soon as possible\n",
      "ASAP\n"
     ]
    }
   ],
   "source": [
    "def myinitial(str) :\n",
    "    return str[0]\n",
    "str = input()\n",
    "a = str.split()\n",
    "s_temp = map(myinitial, a)\n",
    "s = []\n",
    "for x in s_temp:\n",
    "    s.append(x.upper())\n",
    "print(''.join(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. str을 입력받는다.\n",
    "2. str을 공백기준 split해 a에 저장한다.\n",
    "3. a원소 각각(각 단어)에서 0번째 인덱스가 각 단어의 첫번째 글자이다.\n",
    "4. 이를 반환해주는 함수가 myinitial(str) 함수이다. str을 인자로 받고 0번째 인덱스를 반환한다.\n",
    "5. map 함수를 이용해 a리스트의 모든 원소를 myinitial 함수의 인자로 넘겨주고 반환된 첫글자를 s_temp에 저장한다.\n",
    "6. s_temp 각각의 원소들을 upper() 메소드를 이용해 대문자로 치환 후 s리스트에 저장한다.\n",
    "7. join메소드로 각 대문자단어들을 문자열로 합친 후 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 입력 5\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "def myfact(f) :\n",
    "    if f==1:\n",
    "        return 1\n",
    "    return f*myfact(f-1)\n",
    "n = int(input(\"정수 입력 \"))\n",
    "print(myfact(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수를 인자로 받는 myfact 함수에서 받는 인자값이 1일 때(순환종료조건)까지 계속 순환한다. 인자값이 1일 때까지 최초받은 f에서 1씩 뺀 값을 반복해서 넘겨준다.  \n",
    "\n",
    "n = 5 일때)  \n",
    "myfact(5) 실행  \n",
    "myfact(4) 실행  \n",
    "myfact(3) 실행  \n",
    "myfact(2) 실행  \n",
    "myfact(1) 까지 실행 후 순서대로  \n",
    "1반환  \n",
    "2\\*1 반환  \n",
    "3\\*2\\*1 반환  \n",
    "4\\*3\\*2\\*1 반환  \n",
    "최종적으로 5\\*4\\*3\\*2\\*1 반환 후 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(서술형) import string 과 from string import * 의 차이점을 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " import string 과 from string import \\* 는 string모듈에 존재하는 이름들을 현재 이름공간으로 불러온다는 점은 동일하지만, 불러들인 각 이름들을 모듈이름과 함께 사용할 수 있느냐 없느냐의 차이가 있다.\n",
    "예를들어, string 모듈에는 punctuation이라는 문자열이 있다. 이를 import string 방식으로 모듈을 받아오면 앞에 모듈이름이 붙여져있지 않으면 해당 이름을 사용할 수 없다.  \n",
    "하지만 from string import * 방식으로 모듈을 받아오면 punctuation 앞에 string을 붙이지 않고도 사용이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'punctuation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f6f908d19da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'punctuation' is not defined"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import string 형식을 사용하는 경우, 앞에 string이 붙지않으면 에러가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에 string을 붙여 출력하면 문제없이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import *\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from string import * 형식을 사용할 경우 앞에 string을 붙이지 않아도 바로 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYtimes(http://www.nytimes.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Thanksgiving': 15, 'Times': 14, 'York': 12, 'Review': 12, 'Opinion': 11, 'Site': 10, 'PM': 10, 'ET': 10, 'Friday': 9, 'Trump': 8, 'Navigation': 7, 'Magazine': 7, 'Black': 7, 'Books': 7, 'Arts': 6, 'Style': 6, 'Guide': 6, 'News': 5, 'Search': 5, 'Subscribe': 5, '2017': 5, 'Video': 5, 'Business': 5, 'Science': 5, 'Health': 5, 'Food': 5, 'Travel': 5, 'Real': 5, 'Estate': 5, 'Comments': 5, 'Holiday': 5, 'Homes': 5, 'Subscriptions': 5, 'Art': 5, 'World': 4, '»': 4, 'Sections': 4, 'US': 4, 'Tech': 4, 'Sports': 4, 'Flynn': 4, 'Love': 4, 'Living': 4, 'TV': 4, 'Own': 4, 'Lee': 4, 'American': 4, 'Crossword': 4, 'Education': 4, 'Politics': 3, 'NY': 3, 'Mobile': 3, 'Here’s': 3, 'Voices': 3, 'America’s': 3, 'Day': 3, 'Help': 3, 'start': 3, 'day': 3, 'Gift': 3, 'Facebook': 3, 'Boy’s': 3, 'Desire': 3, '‘Call': 3, 'Name’': 3, 'Time': 3, 'Home': 3, '36': 3, 'Hours': 3, 'Spike': 3, 'Netflix': 3, 'Father': 3, 'FarFlung': 3, 'Rise': 3, 'Theater': 3, 'Movies': 3, 'OpEd': 3, '10': 3, 'Dies': 3, 'Feature': 3, 'Sale': 3, 'Todays': 3, 'NYC': 3, 'Events': 3, 'Multimedia': 2, 'NYTimescom': 2, 'Skip': 2, 'Paper': 2, 'search': 2, 'Russia': 2, 'President': 2, 'Tax': 2, 'Plan': 2, 'Lift': 2, 'Union': 2, 'Writing': 2, 'Pay': 2, '‘Gladiator’': 2, 'Battles': 2, 'Conservatives': 2, 'radio': 2, 'Ben': 2, 'Shapiro': 2, 'Blue': 2, 'Head': 2, 'own': 2, 'Washington': 2, 'CARL': 2, 'columnist': 2, 'Argentine': 2, 'Submarine': 2, 'Grief': 2, 'Anger': 2, 'Juan': 2, 'Daily': 2, '360': 2, 'Technology': 2, 'Mugabe': 2, 'Zimbabwe': 2, 'Spokesman': 2, 'Rohingya': 2, 'Forward': 2, 'journalists': 2, '91st': 2, 'Macy’s': 2, 'Parade': 2, 'Hunting': 2, 'holiday': 2, 'Stand': 2, 'Line': 2, 'Psychology': 2, 'Explained': 2, '…': 2, 'Briefing': 2, 'Fix': 2, 'Buy': 2, 'CHEN': 2, 'time': 2, 'series': 2, 'editors': 2, '100': 2, 'Notable': 2, 'Serbia’s': 2, 'War': 2, 'Final': 2, 'Nights': 2, 'SoHo': 2, 'Checks': 2, 'Founder’s': 2, 'Favor': 2, 'Comes': 2, 'Complications': 2, 'Valley': 2, '‘Coco’': 2, 'Brings': 2, 'Pixar': 2, 'Touch': 2, 'Death': 2, '‘Darkest': 2, 'Hour’': 2, 'Theory': 2, 'History': 2, 'Acting': 2, 'Cell': 2, 'cells': 2, 'found': 2, 'damaged': 2, 'Burned': 2, 'Heights': 2, 'help': 2, 'policy': 2, '—': 2, 'Manus': 2, 'Papua': 2, 'Asunción': 2, 'Paraguay': 2, '‘She’s': 2, 'Gotta': 2, 'It’': 2, 'Reboot': 2, 'Twitter': 2, 'Saudi': 2, 'Arabia’s': 2, 'Arab': 2, 'Spring': 2, 'Horses': 2, 'Standing': 2, 'Rock': 2, 'Checkup': 2, 'H1B': 2, 'Visa': 2, 'Won’t': 2, 'Israel': 2, 'Mourn': 2, 'Letters': 2, 'Franken': 2, 'Weeks': 2, 'Insider': 2, 'Play': 2, 'Todayrsquos': 2, 'Puzzle': 2, 'Neediest': 2, 'Loading': 2, 'story': 2, 'Sunday': 2, 'Seas': 2, 'Streaming': 2, 'Services': 2, 'Broadway': 2, 'Market': 2, 'It’s': 2, 'Paradise': 2, 'Photography': 2, 'Fashion': 2, 'Culture': 2, '2': 2, 'Edition': 2, 'Singing': 2, 'Obituaries': 2, 'Weight': 2, 'Television': 2, 'College': 2, 'Jobs': 2, 'Automobiles': 2, 'Index': 2, 'Information': 2, 'Terms': 2, 'Breaking': 1, 'supports': 1, 'Internet': 1, 'Explorer': 1, '9': 1, 'earlier': 1, 'Please': 1, 'upgrade': 1, 'browser': 1, 'LEARN': 1, 'MORE': 1, 'content': 1, 'navigation': 1, 'Log': 1, '0': 1, 'Settings': 1, 'English': 1, '中文': 1, 'Chinese': 1, 'Español': 1, 'Thursday': 1, 'November': 1, '23': 1, 'Today’s': 1, 'Quick': 1, 'Close': 1, 'text': 1, 'input': 1, 'Top': 1, 'Signals': 1, 'Cooperation': 1, 'Investigators': 1, 'MICHAEL': 1, 'SCHMIDT': 1, 'MATT': 1, 'APUZZO': 1, 'MAGGIE': 1, 'HABERMAN': 1, '906': 1, 'Lawyers': 1, 'Michael': 1, 'Trump’s': 1, 'former': 1, 'national': 1, 'security': 1, 'adviser': 1, 'terminated': 1, 'informationsharing': 1, 'agreement': 1, 'president’s': 1, 'legal': 1, 'team': 1, 'move': 1, 'indicates': 1, 'cooperating': 1, 'prosecutors': 1, 'negotiating': 1, 'deal': 1, 'Wages': 1, 'JIM': 1, 'TANKERSLEY': 1, '752': 1, 'administration': 1, 'analysis': 1, 'claims': 1, 'GOP’s': 1, 'proposed': 1, 'corporate': 1, 'tax': 1, 'cut': 1, 'translate': 1, 'extra': 1, '4000': 1, 'takehome': 1, 'pay': 1, 'workers': 1, 'Poor': 1, 'Senators': 1, 'Disagree': 1, 'Minds': 1, 'SABRINA': 1, 'TAVERNISE': 1, '345': 1, 'Rush': 1, 'Limbaugh': 1, 'father': 1, 'listens': 1, 'car': 1, '33': 1, 'graduate': 1, 'Harvard': 1, 'Law': 1, 'School': 1, 'cool': 1, 'kid’s': 1, 'philosopher': 1, 'JASON': 1, 'ZENGERLE': 1, 'liberals': 1, 'tried': 1, 'failed': 1, 'create': 1, 'version': 1, 'conservative': 1, 'talk': 1, 'Crooked': 1, 'Media': 1, 'finally': 1, 'figured': 1, 'Parties': 1, 'Hear': 1, 'Echoes': 1, '2009': 1, 'Majority': 1, 'Flipped': 1, 'HULSE': 1, 'Elements': 1, 'foreshadowed': 1, 'steep': 1, 'losses': 1, 'Democrats': 1, 'eight': 1, 'ago': 1, 'Republicans': 1, 'writes': 1, 'Crew’s': 1, 'Families': 1, 'DANIEL': 1, 'POLITI': 1, 'ERNESTO': 1, 'LONDOÑO': 1, '851': 1, 'Disclosure': 1, 'explosion': 1, 'near': 1, 'San': 1, 'raised': 1, 'fears': 1, '44member': 1, 'crew': 1, 'lost': 1, 'continued': 1, '121': 1, 'Turkeys': 1, 'Kevin': 1, 'Hagen': 1, 'Samsung': 1, 'China': 1, 'Busts': 1, '3': 1, 'Billion': 1, 'Underground': 1, 'Bank': 1, 'Tightens': 1, 'Grip': 1, 'Money': 1, 'Remain': 1, 'Rwanda': 1, 'Offers': 1, 'Host': 1, 'African': 1, 'Migrants': 1, 'Stranded': 1, 'Libya': 1, 'Repatriation': 1, 'Deal': 1, 'Inches': 1, 'Hurdles': 1, 'Background': 1, 'Check': 1, 'System': 1, 'Gun': 1, 'Buyers': 1, 'confidential': 1, 'news': 1, 'tip': 1, 'offers': 1, 'touch': 1, 'provide': 1, 'materials': 1, 'Learn': 1, 'Joy': 1, 'Air': 1, 'Alongside': 1, 'Floating': 1, 'Leviathans': 1, 'edition': 1, 'thronged': 1, 'children': 1, 'marching': 1, 'bands': 1, 'lorded': 1, '48': 1, 'crowdthrilling': 1, 'creatures': 1, 'VINCENT': 1, 'TULLO': 1, 'Updates': 1, 'Bargains': 1, 'Night': 1, 'THE': 1, 'NEW': 1, 'YORK': 1, 'TIMES': 1, '842': 1, 'shopping': 1, 'season': 1, 'begins': 1, 'earnest': 1, 'we’re': 1, 'capturing': 1, 'dealseeking': 1, 'rush': 1, 'looks': 1, 'Grand': 1, 'Buildings': 1, 'Afloat': 1, 'Lipstick': 1, 'Eyeliner': 1, 'CHARLES': 1, 'McDERMID': 1, '832': 1, 'Smarter': 1, 'BRIAN': 1, 'tends': 1, 'prices': 1, 'TVs': 1, 'drop': 1, 'lowest': 1, 'pitfalls': 1, 'playbook': 1, 'snag': 1, 'Watch': 1, 'MARGARET': 1, 'LYONS': 1, 'hopping': 1, 'couch': 1, 'it’s': 1, 'particularly': 1, 'involved': 1, '300': 1, 'gifts': 1, '75': 1, '15': 1, 'categories': 1, 'Journalism': 1, 'matters': 1, 'essential': 1, 'Credit': 1, 'Olimpia': 1, 'Zagnoli': 1, 'year’s': 1, 'notable': 1, 'fiction': 1, 'poetry': 1, 'nonfiction': 1, 'selected': 1, 'Book': 1, 'Reconciliation': 1, 'Embracing': 1, 'Criminals': 1, 'MATTHEW': 1, 'BRUNWASSER': 1, '614': 1, 'Despite': 1, 'conviction': 1, 'Gen': 1, 'Ratko': 1, 'Mladic': 1, 'war': 1, 'crimes': 1, 'collective': 1, 'memory': 1, 'role': 1, 'Yugoslav': 1, 'civil': 1, 'wars': 1, 'forgiving': 1, 'SARAH': 1, 'MASLIN': 1, 'NIR': 1, 'hotel': 1, 'struggled': 1, 'financially': 1, 'soon': 1, 'excise': 1, 'name': 1, 'guests': 1, 'loved': 1, 'brand': 1, 'discounted': 1, 'Organization': 1, 'Exit': 1, 'Struggling': 1, 'Hotel': 1, 'NELLIE': 1, 'BOWLES': 1, '628': 1, 'Wherever': 1, 'Mark': 1, 'Zuckerberg': 1, 'goes': 1, 'Silicon': 1, 'generate': 1, 'housing': 1, 'including': 1, 'RV': 1, 'community': 1, 'residents': 1, 'evicted': 1, 'month': 1, 'Movie': 1, 'Reviews': 1, 'AO': 1, 'SCOTT': 1, 'movie': 1, 'delivers': 1, 'moments': 1, 'cinematic': 1, 'rigor': 1, 'playful': 1, 'popculture': 1, 'erudition': 1, 'deals': 1, 'afterlife': 1, 'don’t': 1, 'scare': 1, 'ZIMMER': 1, 'birth': 1, 'begin': 1, 'anew': 1, 'Scientists': 1, 'biological': 1, 'mechanism': 1, 'underpinning': 1, 'process': 1, 'worms': 1, 'harnessed': 1, 'restore': 1, 'Shared': 1, 'LUIS': 1, 'FERRÉSADURNÍ': 1, '517': 1, 'Dozens': 1, 'families': 1, 'apartments': 1, 'severely': 1, 'fire': 1, 'Hamilton': 1, 'joined': 1, 'dinner': 1, 'Policy': 1, 'Newsletter': 1, 'Andrew': 1, 'Ross': 1, 'Sorkin': 1, 'colleagues': 1, 'sense': 1, 'major': 1, 'business': 1, 'headlines': 1, 'power': 1, 'brokers': 1, 'shape': 1, 'allnew': 1, 'DealBook': 1, 'newsletter': 1, 'Argentina': 1, 'Refugees': 1, 'Trapped': 1, 'Farther': 1, 'Deliverance': 1, 'sent': 1, 'contested': 1, 'detention': 1, 'camp': 1, 'Guinea': 1, 'investigate': 1, 'Australia’s': 1, 'refugee': 1, 'resistance': 1, 'rising': 1, 'Guinea’s': 1, 'Police': 1, 'Storm': 1, 'Island': 1, 'Refugee': 1, 'Camp': 1, 'authorities': 1, 'confronted': 1, 'hundreds': 1, 'asylum': 1, 'seekers': 1, 'destroying': 1, 'possessions': 1, 'demanding': 1, 'leave': 1, 'alternate': 1, 'facilities': 1, '‘Junk’': 1, 'Mines': 1, 'Milken': 1, 'Era': 1, 'Truths': 1, 'Persist': 1, 'Ayad': 1, 'Akhtar’s': 1, 'play': 1, 'portrays': 1, 'financial': 1, 'excesses': 1, '1980s': 1, 'evoke': 1, 'unsettling': 1, 'seek': 1, 'retro': 1, 'restaurants': 1, 'innovative': 1, 'galleries': 1, 'Americanstyle': 1, 'brunches': 1, 'you’ll': 1, 'remade': 1, 'breakthrough': 1, 'film': 1, 'streaming': 1, 'Nola': 1, 'Darling’s': 1, 'love': 1, 'life': 1, 'Editorial': 1, 'Telling': 1, 'Truth': 1, 'Cost': 1, 'civilian': 1, 'casualties': 1, 'appear': 1, 'rise': 1, 'military': 1, 'acknowledging': 1, 'extent': 1, 'Blow': 1, 'Thankfully': 1, 'Recommitting': 1, 'Resistance': 1, 'America': 1, 'Redeemer': 1, 'Nation': 1, 'Dowd': 1, 'Brother': 1, 'Kevin’s': 1, 'Tired': 1, 'Winning': 1, 'Krugman': 1, 'Feeling': 1, 'Thankful': 1, 'Fearful': 1, 'Stephens': 1, 'Gratitude': 1, 'Father’s': 1, 'Lesson': 1, 'Follow': 1, 'THOMAS': 1, 'FRIEDMAN': 1, 'crown': 1, 'prince': 1, 'plans': 1, 'bring': 1, 'level': 1, 'tolerance': 1, 'society': 1, '655': 1, 'Liberals': 1, 'Al': 1, 'Dilemma': 1, 'User': 1, 'Wordplay': 1, 'Watching': 1, 'Raising': 1, 'Twin': 1, '‘Princesses’': 1, 'Special': 1, 'Ingrid': 1, 'Batista': 1, 'twins': 1, 'syndrome': 1, 'committed': 1, 'caring': 1, 'world': 1, 'beauty': 1, '106th': 1, 'Fund': 1, 'provided': 1, 'direct': 1, 'assistance': 1, 'struggling': 1, 'beyond': 1, 'Donate': 1, 'Advertisers': 1, 'times': 1, 'video': 1, 'explore': 1, 'videos': 1, 'Player': 1, 'Inside': 1, 'Nytimescom': 1, 'previous': 1, 'Wintertime': 1, 'Luxuries': 1, 'Seasoned': 1, 'Lounger': 1, 'Fall': 1, 'Africa’s': 1, 'Hated': 1, 'Lady': 1, 'Whales': 1, 'Exfoliate': 1, '5': 1, 'Rules': 1, 'Trip': 1, 'Kids': 1, 'Honduran': 1, 'Candidate': 1, 'Orlando': 1, 'Hernández': 1, 'moving': 1, 'closer': 1, 'authoritarian': 1, 'rule': 1, 'Region': 1, 'Yorkers': 1, 'Fans': 1, '‘Bombshell’': 1, 'Tells': 1, 'Story': 1, 'Hedy': 1, 'Lamarr': 1, 'Owe': 1, 'Innocent': 1, 'Victims': 1, 'Wars': 1, 'kill': 1, 'civilians': 1, 'fail': 1, 'innocent': 1, 'victims': 1, 'fight': 1, 'terrorism': 1, 'harder': 1, '13Word': 1, 'Stories': 1, 'Hopes': 1, 'Dashed': 1, 'Relatives': 1, 'Crew': 1, 'Radiation': 1, 'Cloud': 1, 'Mystery': 1, 'Continue': 1, 'Bargain': 1, 'Bet': 1, 'Thomas': 1, 'Friedman': 1, 'Contributor': 1, 'Provocative': 1, 'Win': 1, 'Photo': 1, 'Billy': 1, 'Kid': 1, 'Bought': 1, 'Flea': 1, 'Worth': 1, 'Millions': 1, 'Native': 1, 'Americans': 1, 'Complicated': 1, 'Victim': 1, 'Russian': 1, 'Propaganda': 1, 'AnythingGoes': 1, 'David': 1, 'Hockney’s': 1, 'Life': 1, 'Painting': 1, 'Spare': 1, 'Exuberant': 1, 'Stephen': 1, 'Shore’s': 1, 'MoMA': 1, 'Survey': 1, 'Restless': 1, 'Reformer': 1, 'Master': 1, 'Corporate': 1, 'Cut': 1, 'Worker': 1, 'Split': 1, 'Indicates': 1, 'Moving': 1, 'Cooperate': 1, 'Mueller': 1, 'Conyers': 1, 'Doesn’t': 1, 'Resign': 1, 'Harassment': 1, 'Claims': 1, 'Lawyer': 1, 'Changing': 1, 'Feminist': 1, 'Cheese': 1, 'Encounters': 1, 'Rapper': 1, 'Chainz': 1, 'Sizes': 1, 'Christie’s': 1, 'G’night': 1, 'Forever': 1, 'Little': 1, 'Edie': 1, 'Grey': 1, 'Gardens': 1, 'Empty': 1, 'Gathered': 1, 'Game': 1, 'Remember': 1, 'Concussion': 1, 'Worries': 1, 'Girls’': 1, 'Lacrosse': 1, 'Headgear': 1, 'Protestants': 1, 'Catholics': 1, 'Meet': 1, 'Cricket': 1, 'Pitch': 1, 'SpongeBob': 1, 'Nickelodeon': 1, 'Aims': 1, 'Splash': 1, 'Bikini': 1, 'Bottom': 1, 'Swim': 1, '‘Harry': 1, 'Clarke’': 1, 'Appealing': 1, 'Helping': 1, 'Dinner': 1, 'Interstellar': 1, 'Visitor': 1, 'Familiar': 1, 'Alien': 1, 'Matter': 1, 'Jon': 1, 'Hendricks': 1, '96': 1, 'Brought': 1, 'Dimension': 1, 'Jazz': 1, 'Maurice': 1, 'Hinchey': 1, 'Congressman': 1, 'Environmental': 1, 'Advocate': 1, '79': 1, 'Naim': 1, 'Suleymanoglu': 1, '50': 1, 'Lifting’s': 1, '‘Pocket': 1, 'Hercules’': 1, '‘Dark’': 1, 'German': 1, 'Series': 1, 'Crosses': 1, 'Border': 1, 'Bold': 1, 'Critic’s': 1, 'Notebook': 1, 'Hiding': 1, '‘Jokes’': 1, 'Abnormal': 1, 'Proteins': 1, 'Discovered': 1, 'Skin': 1, 'Patients': 1, 'Rare': 1, 'Brain': 1, 'Disease': 1, 'Thanks': 1, 'Lot': 1, 'Reasons': 1, 'Eat': 1, 'Cookie': 1, 'Dough': 1, 'Malaria': 1, 'Resists': 1, 'Treatment': 1, 'Experts': 1, 'Warn': 1, 'Global': 1, 'Crisis': 1, 'Looking': 1, 'Sublime': 1, 'Swiss': 1, 'Somewhat': 1, 'Painless': 1, 'Wave': 1, 'Fiction': 1, 'Nigeria': 1, 'Writers': 1, 'Experiment': 1, 'Genres': 1, 'Six': 1, 'Myths': 1, 'Choosing': 1, 'Major': 1, 'Getting': 1, 'Dream': 1, 'Papers': 1, 'Endowments': 1, 'Boom': 1, 'Colleges': 1, 'Bury': 1, 'Earnings': 1, 'Overseas': 1, 'Instead': 1, 'Turkey': 1, 'Reservations': 1, 'Pour': 1, 'LastMinute': 1, 'Buys': 1, 'Wines': 1, 'Caught': 1, 'AI': 1, 'Taught': 1, 'Explain': 1, 'International': 1, 'House': 1, 'Bordeaux': 1, 'France': 1, '800000': 1, 'Ohio': 1, 'Massachusetts': 1, 'Kearny': 1, 'NJ': 1, 'Affordable': 1, 'Ethnically': 1, 'Diverse': 1, 'Upshot': 1, 'Youre': 1, 'Inherit': 1, 'Mother': 1, 'Recipes': 1, 'Googled': 1, 'Care': 1, 'Lost': 1, 'Learned': 1, 'We’re': 1, 'Reading': 1, 'Indian': 1, 'Automaker’s': 1, 'Plant': 1, 'Sign': 1, 'Detroit': 1, 'Comeback': 1, 'Chrysler': 1, 'Pacifica': 1, 'Owners': 1, 'Minivans': 1, 'Suddenly': 1, 'Shut': 1, 'Wheels': 1, 'Near': 1, 'Future': 1, 'Driving': 1, 'Eyes': 1, 'Hands': 1, 'Sweet': 1, 'Rewards': 1, 'Bitter': 1, 'Generation': 1, 'Character': 1, 'Actors': 1, 'Mourning': 1, 'Alaïa': 1, 'Designer’s': 1, 'Friends': 1, 'Collaborators': 1, 'React': 1, 'City': 1, 'STEFANOS': 1, 'week’s': 1, 'listings': 1, 'Gramercy': 1, 'Park': 1, 'Hunters': 1, 'Queens': 1, 'Brooklyn': 1, 'Rent': 1, 'Mortgage': 1, 'Calculator': 1, 'Emailed': 1, 'Viewed': 1, 'Trending': 1, 'Recommended': 1, 'Page': 1, 'Corrections': 1, 'Columnists': 1, 'Editorials': 1, 'Contributors': 1, 'Design': 1, 'Dance': 1, 'Music': 1, 'Weddings': 1, 'Celebrations': 1, 'Listings': 1, 'Reader': 1, 'Center': 1, 'Classifieds': 1, 'Tools': 1, 'NYT': 1, 'Store': 1, 'Journeys': 1, 'Manage': 1, 'Account': 1, 'NYTCo': 1, 'Delivery': 1, 'Digital': 1, 'Email': 1, 'Newsletters': 1, 'Alerts': 1, 'Rate': 1, 'Applications': 1, 'Replica': 1, 'copy': 1, 'Company': 1, 'Contact': 1, 'Advertise': 1, 'Ad': 1, 'Choices': 1, 'Privacy': 1, 'Service': 1, 'Map': 1, 'Feedback': 1, 'View': 1, 'Version': 1}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from urllib import request \n",
    "import string\n",
    "\n",
    "url = 'http://www.nytimes.com'\n",
    "url2 = 'http://edition.cnn.com'\n",
    "url3 = 'http://www.foxnews.com'\n",
    "url4 = 'http://www.chron.com'\n",
    "url5 = 'http://www.latimes.com'\n",
    "f = request.urlopen(url)\n",
    "source_bytes = f.read()\n",
    "source = source_bytes.decode('utf-8')\n",
    "with open('www.nytimes.com.html','w',encoding='utf8') as f:\n",
    "    f.write(source)\n",
    "a = source\n",
    "cnt=0\n",
    "cnt\n",
    "list = []\n",
    "\n",
    "\n",
    "while(cnt != len(a)) :\n",
    "    \n",
    "        if a[cnt] == '<' :\n",
    "            if(a[cnt+1] == '!' and a[cnt+2]=='-') : #주석 삭제\n",
    "                cnt+=3\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt] == '-' and a[cnt+1] == '>'):\n",
    "                        cnt+=1\n",
    "                        break\n",
    "            elif(a[cnt+1:cnt+7] == \"script\" ) : #스크립트 삭제\n",
    "                cnt+=7\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+8] == \"/script>\"):\n",
    "                        cnt+=8\n",
    "                        break\n",
    "                        \n",
    "            elif(a[cnt+1:cnt+6]) == \"style\" : ##css 삭제\n",
    "                cnt+=6\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+6]) == '/style':\n",
    "                        cnt+=6\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    \n",
    "            else:\n",
    "                while(a[cnt] != '>'): #HTML 삭제\n",
    "                    cnt+=1\n",
    "                    \n",
    "        \n",
    "        elif  a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt]!=' ' and a[cnt] !='\\n' :\n",
    "            start = cnt\n",
    "            while a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt] !=' ' and a[cnt] !='\\n' :\n",
    "                    cnt+=1\n",
    "                    if(cnt==len(a)):\n",
    "                            break\n",
    "                        \n",
    "            end = cnt\n",
    "            list.append(a[start:end])\n",
    "            \n",
    "        else :\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "c=[]\n",
    "for x in string.punctuation: #구두문자 리스트화\n",
    "    c.append(x)\n",
    "c.append(\"\\r\")\n",
    "c.append(\"nbsp\")\n",
    "c.append(\"raquo\")\n",
    "\n",
    "for x in range(len(list)) : #구두문자가 list의 원소안에 포함되어있을 경우\n",
    "    for k in c:\n",
    "        if k in list[x]:\n",
    "            list[x] = list[x].replace(k,'') #구두문자를 없앤다\n",
    "    \n",
    "\n",
    "list.remove('') #구두문자만 있었을 경우 공백만 남으므로 공백 없애줌\n",
    "            \n",
    "dic = dict()\n",
    "for x in list:\n",
    "    if x not in dic.keys(): #list의 원소가 사전에 없으면 추가\n",
    "        dic[x] = 1\n",
    "    elif x in dic.keys(): #이미 있는 원소면 1추가\n",
    "        dic[x] += 1\n",
    "        \n",
    "f = open(\"StopwordList.txt\",\"r\")\n",
    "stopword = f.readlines()\n",
    "stopword_title = []\n",
    "for i in range(len(stopword)):\n",
    "    stopword[i] = stopword[i][:-1]\n",
    "for i in range(len(stopword)):\n",
    "    stopword_title.append(stopword[i].title())\n",
    "\n",
    "dict_key_list = []\n",
    "for i in dic.keys():\n",
    "    dict_key_list.append(i)\n",
    "for ele in stopword :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "for ele in stopword_title :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "while '' in dic.keys():\n",
    "    del dic['']\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key = lambda x : x[1], reverse = True)\n",
    "\n",
    "url_frequency = \"www.nytimes.com.words.frequency\"\n",
    "with open(url_frequency,\"wb\") as f:\n",
    "     pickle.dump(dict(dic_sorted), f)\n",
    "    \n",
    "with open(url_frequency,\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (http://edition.cnn.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'US': 14, 'CNN': 11, 'International': 11, 'Video': 8, 'TV': 5, 'Arabic': 4, 'Set': 4, 'edition': 4, 'preference': 4, 'Confirm': 4, 'Africa': 4, 'Business': 4, 'Luxury': 4, 'Culture': 4, 'Features': 4, 'News': 3, 'World': 3, 'Weather': 3, 'Home': 3, 'Regions': 3, 'Politics': 3, 'Tech': 3, 'Sport': 3, 'Health': 3, 'VR': 3, 'Edition': 3, 'Español': 3, 'Breaking': 2, 'Entertainment': 2, 'Americas': 2, 'Asia': 2, 'China': 2, 'Europe': 2, 'Middle': 2, 'East': 2, 'Opinion': 2, '45': 2, 'Congress': 2, 'Security': 2, 'Nine': 2, 'Trumpmerica': 2, 'Markets': 2, 'Stars': 2, 'Screen': 2, 'Binge': 2, 'Media': 2, 'Gadgets': 2, 'Future': 2, 'Startups': 2, 'Football': 2, 'Tennis': 2, 'Equestrian': 2, 'Golf': 2, 'Judo': 2, 'Horse': 2, 'Racing': 2, 'Motorsport': 2, 'Sailing': 2, 'Skiing': 2, 'Olympics': 2, 'Destinations': 2, 'Food': 2, 'amp': 2, 'Drink': 2, 'Play': 2, 'Stay': 2, 'Videos': 2, 'Arts': 2, 'Design': 2, 'Fashion': 2, 'Architecture': 2, 'Autos': 2, 'Diet': 2, 'Fitness': 2, 'Living': 2, 'Parenting': 2, 'Family': 2, 'Vital': 2, 'Signs': 2, 'Freedom': 2, 'Project': 2, 'Impact': 2, 'Inside': 2, '2': 2, 'degrees': 2, 'Heroes': 2, 'news': 2, 'Feature': 2, 'HLN': 2, 'schedule': 2, 'Worldwide': 2, 'CNNVR': 2, 'Watch': 2, 'Archives': 2, 'More…': 2, 'Profiles': 2, 'Leadership': 2, 'Pressroom': 2, 'Partner': 2, 'sites': 2, 'iReport': 2, 'Money': 1, 'Travel': 1, 'Style': 1, 'Live': 1, 'Search': 1, 'Espantildeol': 1, 'Facebook': 1, 'Twitter': 1, 'Instagram': 1, 'copy2017CableNewsNetwork': 1, 'TurnerBroadcastingSystemInc': 1, 'AllRightsReserved': 1, 'CNNSanstradeampcopy2016CableNewsNetwork': 1, 'Terms': 1, 'Privacy': 1, 'Policy': 1, 'AdChoices': 1, 'MSA': 1, 'Statement': 1, 'Advertise': 1, 'Store': 1, 'Newsletters': 1, 'Help': 1, 'Transcripts': 1, 'License': 1, 'Footage': 1, 'Newsource': 1}\n"
     ]
    }
   ],
   "source": [
    "f = request.urlopen(url2)\n",
    "source_bytes = f.read()\n",
    "source = source_bytes.decode('utf-8')\n",
    "with open('edition.cnn.com.html','w',encoding='utf8') as f:\n",
    "    f.write(source)\n",
    "a = source\n",
    "cnt=0\n",
    "cnt\n",
    "list = []\n",
    "\n",
    "\n",
    "while(cnt != len(a)) :\n",
    "    \n",
    "        if a[cnt] == '<' :\n",
    "            if(a[cnt+1] == '!' and a[cnt+2]=='-') : #주석 삭제\n",
    "                cnt+=3\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt] == '-' and a[cnt+1] == '>'):\n",
    "                        cnt+=1\n",
    "                        break\n",
    "            elif(a[cnt+1:cnt+7] == \"script\" ) : #스크립트 삭제\n",
    "                cnt+=7\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+8] == \"/script>\"):\n",
    "                        cnt+=8\n",
    "                        break\n",
    "                        \n",
    "            elif(a[cnt+1:cnt+6]) == \"style\" : ##css 삭제\n",
    "                cnt+=6\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+6]) == '/style':\n",
    "                        cnt+=6\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    \n",
    "            else:\n",
    "                while(a[cnt] != '>'): #HTML 삭제\n",
    "                    cnt+=1\n",
    "                    \n",
    "        \n",
    "        elif  a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt]!=' ' and a[cnt] !='\\n' :\n",
    "            start = cnt\n",
    "            while a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt] !=' ' and a[cnt] !='\\n' :\n",
    "                    cnt+=1\n",
    "                    if(cnt==len(a)):\n",
    "                            break\n",
    "                        \n",
    "            end = cnt\n",
    "            list.append(a[start:end])\n",
    "            \n",
    "        else :\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "c=[]\n",
    "for x in string.punctuation: #구두문자 리스트화\n",
    "    c.append(x)\n",
    "c.append(\"\\r\")\n",
    "c.append(\"nbsp\")\n",
    "c.append(\"raquo\")\n",
    "\n",
    "for x in range(len(list)) : #구두문자가 list의 원소안에 포함되어있을 경우\n",
    "    for k in c:\n",
    "        if k in list[x]:\n",
    "            list[x] = list[x].replace(k,'') #구두문자를 없앤다\n",
    "    \n",
    "\n",
    "list.remove('') #구두문자만 있었을 경우 공백만 남으므로 공백 없애줌\n",
    "            \n",
    "dic = dict()\n",
    "for x in list:\n",
    "    if x not in dic.keys(): #list의 원소가 사전에 없으면 추가\n",
    "        dic[x] = 1\n",
    "    elif x in dic.keys(): #이미 있는 원소면 1추가\n",
    "        dic[x] += 1\n",
    "        \n",
    "f = open(\"StopwordList.txt\",\"r\")\n",
    "stopword = f.readlines()\n",
    "stopword_title = []\n",
    "for i in range(len(stopword)):\n",
    "    stopword[i] = stopword[i][:-1]\n",
    "for i in range(len(stopword)):\n",
    "    stopword_title.append(stopword[i].title())\n",
    "\n",
    "dict_key_list = []\n",
    "for i in dic.keys():\n",
    "    dict_key_list.append(i)\n",
    "for ele in stopword :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "for ele in stopword_title :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "while '' in dic.keys():\n",
    "    del dic['']\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key = lambda x : x[1], reverse = True)\n",
    "url_frequency = \"edition.cnn.com.words.frequency\"\n",
    "with open(url_frequency,\"wb\") as f:\n",
    "    pickle.dump(dict(dic_sorted), f)\n",
    "    \n",
    "with open(url_frequency,\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FoxNews(http://www.foxnews.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'US': 38, 'News': 31, 'Thanksgiving': 31, 'View': 27, 'Entertainment': 22, 'Opinion': 21, 'Fox': 18, 'Health': 18, 'Lifestyle': 16, 'Trump': 16, 'World': 15, 'amp': 13, 'Markets': 12, 'Real': 12, 'Features': 11, 'Estate': 11, 'Politics': 9, 'Video': 9, 'Tech': 9, 'Americax27s': 9, 'Food': 8, 'Drink': 8, 'Cars': 8, 'Trucks': 8, 'Business': 7, 'Outdoors': 7, 'Newsroom': 7, 'holiday': 7, 'report': 7, 'Black': 7, 'Friday': 7, 'Sports': 7, 'TV': 6, 'House': 6, 'Travel': 6, 'Science': 6, 'Clips': 6, 'tax': 6, '2017': 6, 'America': 6, 'November': 6, 'caught': 5, 'Style': 5, 'Rep': 5, 'Americans': 5, 'Day': 5, 'police': 5, 'test': 5, '5': 5, 'NFL': 5, 'deals': 5, 'Keith': 5, 'family': 5, 'Watch': 4, 'doing': 4, 'drugs': 4, 'Military': 4, 'Economy': 4, 'Senate': 4, 'Elections': 4, 'Home': 4, 'Air': 4, 'Earth': 4, 'Live': 4, 'Email': 4, 'Policy': 4, 'rights': 4, 'Instagram': 4, 'Manafort': 4, 'Russia': 4, 'Weinstein': 4, 'game': 4, 'teacher': 4, 'murder': 4, 'thanks': 4, 'line': 4, 'California': 4, 'fight': 4, '23': 4, 'name': 4, 'makeup': 4, 'Radio': 3, 'search': 3, 'Flynn': 3, 'Global': 3, 'Executive': 3, 'Technology': 3, 'Leaders': 3, 'Fitness': 3, 'Wellbeing': 3, 'Beauty': 3, 'Security': 3, 'Picks': 3, 'market': 3, 'data': 3, 'minutes': 3, 'Twitter': 3, 'world': 3, 'Tom': 3, 'Reed': 3, 'relief': 3, 'Woman': 3, 'helped': 3, 'explicit': 3, 'Barton': 3, 'passenger': 3, 'travel': 3, 'cut': 3, 'Christmas': 3, 'Walid': 3, 'Phares': 3, 'NKorea': 3, 'strategy': 3, 'significance': 3, 'defector': 3, 'ties': 3, 'team': 3, 'amid': 3, 'Turkey': 3, 'federal': 3, 'party': 3, 'Texas': 3, 'day': 3, 'shooting': 3, 'NOT': 3, 'arrested': 3, 'sex': 3, 'Franken': 3, 'allegations': 3, 'convicted': 3, '1978': 3, 'double': 3, 'pardoned': 3, 'calls': 3, 'hunt': 3, '3': 3, 'missing': 3, '50': 3, 'moments': 3, 'flat': 3, 'Wisconsin': 3, 'deer': 3, 'buck': 3, 'energy': 3, 'resources': 3, 'Native': 3, 'benefit': 3, 'Thankfulness': 3, 'powerful': 3, 'tool': 3, 'despair': 3, 'lower': 3, 'x27insanex27': 3, 'deal': 3, '6': 3, 'bags': 3, 'life': 3, 'Vietnam': 3, 'veteran': 3, 'x27I': 3, 'linex27': 3, 'debuts': 3, 'business': 3, 'restaurant': 3, 'Thursday': 3, 'Wednesday': 3, 'thankful': 3, 'military': 3, 'store': 3, 'kitchen': 3, 'court': 3, 'star': 3, 'video': 3, 'shares': 3, 'woman': 3, 'time': 3, 'Photos': 2, 'Moscow': 2, 'Crime': 2, 'Education': 2, 'Terror': 2, 'Immigration': 2, 'Personal': 2, 'Freedoms': 2, 'UN': 2, 'Conflicts': 2, 'Terrorism': 2, 'Disasters': 2, 'Environment': 2, 'Religion': 2, 'Scandals': 2, 'Judiciary': 2, 'Foreign': 2, 'policy': 2, 'Polls': 2, 'Celebrity': 2, 'Movies': 2, 'Music': 2, 'Archaeology': 2, 'Space': 2, 'Planet': 2, 'Wild': 2, 'Nature': 2, 'Natural': 2, 'Dinosaurs': 2, 'Innovation': 2, 'Drones': 2, 'Computers': 2, 'Games': 2, 'Healthy': 2, 'Living': 2, 'Medical': 2, 'Research': 2, 'Mental': 2, 'Cancer': 2, 'Heart': 2, 'Childrens': 2, 'Editors': 2, 'Personalities': 2, 'Careers': 2, 'College': 2, 'Students': 2, 'Advertise': 2, 'Ad': 2, 'Choices': 2, 'Media': 2, 'Relations': 2, 'Insider': 2, 'Nation': 2, 'Newsletters': 2, 'Alerts': 2, 'Podcasts': 2, 'Apps': 2, 'Products': 2, 'Terms': 2, 'Privacy': 2, 'Closed': 2, 'Captioning': 2, 'Help': 2, 'material': 2, 'published': 2, 'broadcast': 2, 'rewritten': 2, 'redistributed': 2, 'copy2017': 2, 'FOX': 2, 'Network': 2, 'LLC': 2, 'reserved': 2, 'delayed': 2, '20': 2, 'Facebook': 2, 'Google': 2, 'RSS': 2, 'Exclusive': 2, '509': 2, '048': 2, 'raises': 2, 'thousands': 2, 'homeless': 2, '228': 2, 'Police': 2, 'investigate': 2, 'release': 2, 'photo': 2, '535': 2, 'makes': 2, 'visit': 2, 'Coast': 2, 'Guard': 2, 'station': 2, '338': 2, 'Knowing': 2, '1223': 2, 'outnumbered': 2, '510': 2, 'legal': 2, 'probe': 2, 'White': 2, 'reportedly': 2, 'lawyers': 2, 'Special': 2, 'Robert': 2, 'election': 2, 'campaign': 2, 'Mueller': 2, 'Paul': 2, 'indicted': 2, 'Uma': 2, 'Thurman': 2, 'rips': 2, 'Harvey': 2, 'post': 2, 'list': 2, 'claims': 2, 'leg': 2, 'surgery': 2, 'gruesome': 2, 'injury': 2, 'breaks': 2, 'suspect': 2, 'cop': 2, 'shot': 2, 'own': 2, 'officer': 2, '2': 2, 'camera': 2, 'classroom': 2, 'school': 2, 'Utah': 2, 'admits': 2, 'women': 2, 'groping': 2, 'Las': 2, 'Vegas': 2, 'fired': 2, 'Navy': 2, 'crash': 2, 'wife': 2, 'charged': 2, 'memorable': 2, 'threatened': 2, 'harassment': 2, 'despite': 2, 'x27blue': 2, 'lawsx27': 2, 'StateLocal': 2, 'Rocket': 2, 'launch': 2, 'prove': 2, 'hunter': 2, 'meets': 2, 'friendly': 2, '8point': 2, 'political': 2, 'debates': 2, 'recipe': 2, 'stuffing': 2, 'values': 2, 'kids': 2, 'Michael': 2, 'tensions': 2, 'Close': 2, 'Turkeys': 2, 'sitcom': 2, 'episodes': 2, 'specials': 2, 'smartphone': 2, 'Butterball': 2, 'questions': 2, 'avoid': 2, 'secrets': 2, 'Stewart': 2, 'reveal': 2, 'National': 2, 'Parks': 2, 'offering': 2, 'fix': 2, 'turkey': 2, 'Donx27t': 2, 'Womanx27s': 2, 'snack': 2, 'hack': 2, 'law': 2, 'Kate': 2, 'necklace': 2, 'American': 2, 'Apprenticeship': 2, 'program': 2, 'aims': 2, 'assist': 2, 'veteransx27': 2, 'transition': 2, 'civilian': 2, 'Toby': 2, 'draw': 2, 'Veterans': 2, 'Lara': 2, 'love': 2, 'Report': 2, '22': 2, '1779': 2, 'lessons': 2, 'millionaires': 2, 'knees': 2, 'Facing': 2, 'midst': 2, 'loss': 2, 'brings': 2, 'Storage': 2, '101': 2, 'tools': 2, 'flatware': 2, 'hits': 2, 'design': 2, 'media': 2, 'drive': 2, 'stalking': 2, 'VA': 2, 'WWII': 2, 'help': 2, 'dies': 2, 'secret': 2, 'awareness': 2, 'watch': 2, 'Urbanx27s': 2, 'recalls': 2, '10': 2, 'Cyber': 2, 'review': 2, 'Itx27s': 2, 'reports': 2, 'prosecutor': 2, 'NYC': 2, 'terror': 2, 'charges': 2, 'fans': 2, '7Eleven': 2, 'lowcost': 2, 'wish': 2, 'receives': 2, 'birthday': 2, 'photos': 2, 'message': 2, 'Parade': 2, 'DNA': 2, 'Al': 2, 'Moore': 2, 'Alabama': 2, 'camp': 2, 'ban': 2, 'Victoriax27s': 2, 'Secret': 2, 'models': 2, 'prepared': 2, 'runway': 2, 'Holocaust': 2, 'Child': 2, 'allegedly': 2, 'destroys': 2, '1300': 2, 'Sephora': 2, 'x27finger': 2, 'paintx27': 2, 'sports': 2, 'widow': 2, 'ahead': 2, 'hours': 2, 'safe': 2, 'car': 2, 'stuck': 2, 'tracks': 2, 'NBA': 2, 'Olympic': 2, 'gymnast': 2, 'Gabby': 2, 'Douglas': 2, 'abused': 2, 'doctor': 2, 'Asian': 2, 'stocks': 2, 'Blake': 2, 'Breaking': 1, 'Updates': 1, 'Headlines': 1, 'Videos': 1, 'Expand': 1, 'Collapse': 1, 'Login': 1, '9776': 1, 'Hot': 1, 'Topics': 1, 'flipped': 1, 'Manafortx27s': 1, 'meetings': 1, 'Teacher': 1, 'class': 1, 'SP500': 1, 'ICOMP': 1, 'IDJI': 1, 'Sponsored': 1, 'HAS': 1, 'FLYNN': 1, 'FLIPPED': 1, 'ExNational': 1, 'adviser': 1, 'cuts': 1, 'Attorneys': 1, 'former': 1, 'insider': 1, 'informed': 1, 'presidentx27s': 1, 'discuss': 1, 'Counsel': 1, 'Muellerx27s': 1, 'investigation': 1, 'Russian': 1, 'activities': 1, '2016': 1, 'investigating': 1, 'alleged': 1, 'Flynnlinked': 1, 'plan': 1, 'hand': 1, 'cleric': 1, 'Judge': 1, 'Nap': 1, 'x27putting': 1, 'squeezex27': 1, '18': 1, 'trips': 1, 'met': 1, 'Putin': 1, 'allies': 1, 'prior': 1, 'running': 1, 'Rick': 1, 'Gates': 1, 'grand': 1, 'jury': 1, 'x27YOU': 1, 'DONx27T': 1, 'DESERVE': 1, 'BULLETx27': 1, 'names': 1, 'gathered': 1, 'intel': 1, 'silence': 1, 'Netflix': 1, 'partner': 1, 'Company': 1, 'annual': 1, 'Golden': 1, 'Globes': 1, 'GRUESOME': 1, 'INJURY': 1, 'GRAPHIC': 1, 'VIDEO': 1, 'WARNING': 1, 'Miss': 1, 'quarterback': 1, 'suffers': 1, 'horrific': 1, 'break': 1, 'Bears': 1, 'tight': 1, 'undergoes': 1, 'emergency': 1, 'Gordon': 1, 'Hayward': 1, 'ankle': 1, 'CelticsCavaliers': 1, 'COP': 1, 'KILLER': 1, 'CAPTURED': 1, 'Manhunt': 1, 'slaying': 1, 'trooper': 1, 'Baltimore': 1, 'gun': 1, 'scheduled': 1, 'testify': 1, 'Female': 1, 'Georgia': 1, 'killed': 1, 'x27ambushx27': 1, 'suspects': 1, 'custody': 1, 'ON': 1, 'THE': 1, 'CURRICULUM': 1, 'English': 1, '24': 1, 'Maryland': 1, 'selling': 1, 'quizzed': 1, 'students': 1, 'lives': 1, 'drug': 1, 'placed': 1, 'leave': 1, 'x27made': 1, 'feel': 1, 'badlyx27': 1, 'shooter': 1, '1100': 1, 'rounds': 1, 'rampage': 1, 'sheriff': 1, 'soldiers': 1, 'Philippine': 1, 'Sea': 1, 'Lost': 1, 'vessel': 1, 'x27piece': 1, 'crapx27': 1, 'sailorx27s': 1, 'explosion': 1, 'detected': 1, 'North': 1, 'Koreans': 1, 'propaganda': 1, 'x27Dear': 1, 'Leaderx27': 1, 'sunglasses': 1, 'x27Voodoo': 1, 'priestx27': 1, 'stabbing': 1, 'pit': 1, 'bull': 1, 'times': 1, 'Oregon': 1, 'x27Jay': 1, 'x27Clerksx27x27': 1, 'burglar': 1, 'string': 1, 'package': 1, 'thefts': 1, 'Football': 1, 'players': 1, 'beat': 1, 'teammate': 1, 'unconscious': 1, 'authorities': 1, 'Editorx27s': 1, 'x27Nazi': 1, 'dungeonx27': 1, 'gang': 1, 'chained': 1, 'rape': 1, 'UC': 1, 'Berkeley': 1, 'conservative': 1, 'student': 1, 'sues': 1, 'Antifa': 1, 'threats': 1, 'Customers': 1, 'Lessons': 1, 'learn': 1, 'Jonathan': 1, 'Den': 1, 'Hartog': 1, 'Leave': 1, 'Please': 1, 'Mitzi': 1, 'Perdue': 1, 'Levin': 1, 'Jean': 1, 'Card': 1, 'Joshua': 1, 'Rogers': 1, 'Fred': 1, 'Fleitz': 1, 'Podcast': 1, 'Rundown': 1, 'Play': 1, 'Pause': 1, 'Volume': 1, 'delivered': 1, 'inbox': 1, 'daily': 1, 'Weve': 1, 'added': 1, 'mailing': 1, 'email': 1, 'address': 1, 'valid': 1, 'Funniest': 1, 'hotlinex27s': 1, 'craziest': 1, 'salmonella': 1, 'poisoning': 1, 'Stay': 1, 'healthy': 1, 'traveling': 1, 'Shocking': 1, 'x27Buffyx27': 1, 'stalker': 1, '‘Jurassic': 1, '2’': 1, 'BIG': 1, 'dry': 1, 'lumpy': 1, 'gravy': 1, 'shop': 1, 'reading': 1, 'Longnecked': 1, 'dino': 1, 'record': 1, 'Girl': 1, 'JLaw': 1, 'single': 1, 'Kidnapped': 1, 'heiress': 1, 'shocker': 1, 'Selena’s': 1, 'lifeordeath': 1, 'moment': 1, 'wears': 1, 'Queen’s': 1, 'Previous': 1, 'Proud': 1, 'longtime': 1, 'promise': 1, 'late': 1, 'fellow': 1, 'Marine': 1, 'x27Vegas': 1, 'Strongx27': 1, 'F15': 1, 'fighter': 1, 'jet': 1, 'Nevada': 1, 'air': 1, 'commended': 1, 'helping': 1, 'prevent': 1, 'suicides': 1, 'Vice': 1, 'President': 1, 'Pence': 1, 'cleans': 1, 'Memorial': 1, 'Success': 1, 'Juliex27s': 1, 'Building': 1, 'foundation': 1, 'natural': 1, 'food': 1, 'empire': 1, 'roadwork': 1, 'shut': 1, 'Amishinspired': 1, 'Urban': 1, 'Southern': 1, 'leather': 1, 'brand': 1, 'success': 1, '0342': 1, 'Time': 1, 'Pivot': 1, 'Husband': 1, 'opportunity': 1, 'virtual': 1, 'reality': 1, 'Weathering': 1, 'nasty': 1, 'storm': 1, 'Secrets': 1, 'Superstorm': 1, 'Sandy': 1, 'revive': 1, 'community': 1, 'Episodes': 1, '3952': 1, 'Story': 1, 'wMartha': 1, 'MacCallum': 1, '4433': 1, 'Bret': 1, 'Baier': 1, '4002': 1, 'Five': 1, '4054': 1, 'Night': 1, '4105': 1, 'Ingraham': 1, 'Angle': 1, '4628': 1, 'Hannity': 1, 'prep': 1, 'gatherings': 1, 'season': 1, 'Obama': 1, 'vacation': 1, 'home': 1, '1775': 1, 'million': 1, 'Katy': 1, 'Perry': 1, 'wins': 1, 'battle': 1, 'Los': 1, 'Angeles': 1, 'property': 1, 'George': 1, 'Straitx27s': 1, 'custombuilt': 1, 'mansion': 1, 'sale': 1, 'Autos': 1, 'Automotive': 1, 'Mazda': 1, 'CX5': 1, 'sporty': 1, 'utility': 1, 'vehicle': 1, 'Tony': 1, 'fan': 1, 'threatening': 1, 'NASCAR': 1, 'Ken': 1, 'Block': 1, 'tells': 1, 'story': 1, 'x27Top': 1, 'Gearx27': 1, 'stunt': 1, 'gone': 1, 'wrong': 1, 'near': 1, 'war': 1, 'memorial': 1, 'Toyota': 1, 'Highlander': 1, 'hybrid': 1, 'SUV': 1, 'delivers': 1, 'MPGs': 1, 'Confederate': 1, 'Motors': 1, 'officially': 1, 'announces': 1, 'change': 1, 'Saluting': 1, 'Troops': 1, 'study': 1, 'parasite': 1, 'killing': 1, 'vets': 1, 'nurses': 1, 'laugh': 1, 'Colorado': 1, 'kept': 1, 'wait': 1, 'lists': 1, 'vetsx27': 1, 'mental': 1, 'heath': 1, 'care': 1, 'Top': 1, 'Army': 1, 'x27significant': 1, 'amountx27': 1, 'soldiersx27': 1, 'crime': 1, 'reported': 1, 'feds': 1, 'Vets': 1, 'walk': 1, 'honor': 1, 'fallen': 1, 'brothers': 1, 'raise': 1, 'suicide': 1, 'classic': 1, 'x27Buffy': 1, 'Vampire': 1, 'Slayer': 1, 'set': 1, 'Mondayx27s': 1, 'biggest': 1, 'savings': 1, 'x27Call': 1, 'Duty': 1, 'WWIIx27': 1, 'basics': 1, 'Bosch': 1, 'brakes': 1, 'form': 1, 'auto': 1, 'emissions': 1, 'iDisc': 1, 'Star': 1, 'Wars': 1, 'Jedi': 1, 'Challenges': 1, 'lot': 1, 'fun': 1, 'SoHo': 1, 'hotel': 1, 'drop': 1, 'x27Trumpx27': 1, 'slow': 1, 'girl': 1, '6point': 1, 'statex27s': 1, 'hunting': 1, 'x27Extremely': 1, 'drunkx27': 1, 'EasyJet': 1, 'tried': 1, 'bite': 1, 'x27urinated': 1, 'himselfx27': 1, 'Sayfullo': 1, 'Saipov': 1, 'ridiculous': 1, 'hotline': 1, 'answered': 1, 'common': 1, 'cooking': 1, 'mistakes': 1, 'McDonaldx27s': 1, 'tearing': 1, 'museum': 1, 'site': 1, 'Olive': 1, 'Garden': 1, 'baby': 1, 'movietheater': 1, 'goes': 1, 'viral': 1, 'Values': 1, 'Australia': 1, 'strange': 1, 'experience': 1, 'Holiday': 1, 'leftovers': 1, 'toss': 1, 'Abortion': 1, 'rates': 1, 'hit': 1, 'historic': 1, 'low': 1, 'CDC': 1, 'Paramedics': 1, 'grant': 1, 'patientx27s': 1, 'final': 1, 'beach': 1, 'Toddler': 1, 'kidney': 1, 'transplant': 1, 'initial': 1, 'procedure': 1, 'stalled': 1, 'dadx27s': 1, 'probation': 1, 'violation': 1, 'listeria': 1, 'diseases': 1, 'flying': 1, 'holidays': 1, 'Baby': 1, 'born': 1, 'weeks': 1, 'mom': 1, 'grandma': 1, '0509': 1, '0457': 1, 'HQ': 1, 'Ralph': 1, 'Peters': 1, 'ISIS': 1, 'Iranx27s': 1, 'influence': 1, '0510': 1, '0209': 1, 'WaPo': 1, 'share': 1, '0602': 1, 'greets': 1, 'service': 1, '0235': 1, 'Friends': 1, 'Pastor': 1, 'Jeffress': 1, 'Suspect': 1, 'fatal': 1, 'captured': 1, 'suspends': 1, 'sailors': 1, 'plane': 1, 'NYPD': 1, 'weapon': 1, 'x27Vapor': 1, 'Wakex27': 1, 'retrievers': 1, 'credits': 1, 'troops': 1, 'advances': 1, 'Indiana': 1, 'busted': 1, 'crossed': 1, 'ExRep': 1, 'Hinchey': 1, 'pushed': 1, 'protect': 1, 'environment': 1, 'docs': 1, 'closer': 1, 'Despite': 1, 'customers': 1, 'GOP': 1, 'committees': 1, 'remain': 1, 'odds': 1, 'nears': 1, 'Papua': 1, 'Guinea': 1, 'officials': 1, 'remove': 1, 'refugees': 1, 'PNG': 1, 'removes': 1, 'closed': 1, 'immigration': 1, 'Nepal': 1, 'hopes': 1, 'elections': 1, 'people': 1, 'voice': 1, 'Italian': 1, 'antimafia': 1, 'mafias': 1, 'cooperating': 1, 'Honduras': 1, 'president': 1, 'seeks': 1, '2nd': 1, 'term': 1, 'constitutional': 1, 'Family': 1, 'national': 1, 'anthem': 1, 'protests': 1, 'teaching': 1, 'children': 1, 'feast': 1, 'Focus': 1, 'unites': 1, 'Planning': 1, 'Macyx27s': 1, 'spectacle': 1, 'x27American': 1, 'Chopperx27': 1, 'Teutul': 1, 'father': 1, 'favor': 1, 'Suzanne': 1, 'Venker': 1, 'x27Marrying': 1, 'downx27': 1, 'celebrate': 1, 'Improvement': 1, '8': 1, 'consider': 1, 'adding': 1, 'carpet': 1, 'bedroom': 1, 'shelves': 1, 'efficiency': 1, 'style': 1, 'pros': 1, 'cons': 1, '9': 1, 'popular': 1, 'bathroom': 1, 'mirror': 1, 'options': 1, '101yearold': 1, 'survived': 1, 'cancer': 1, 'celebrates': 1, 'serious': 1, 'workout': 1, 'difference': 1, 'vegan': 1, 'crueltyfree': 1, 'cosmetics': 1, 'bodylength': 1, 'birthmark': 1, '‘sexy’': 1, 'selfie': 1, 'promote': 1, 'Silicone': 1, 'butt': 1, 'injections': 1, 'deadly': 1, 'FDA': 1, 'warns': 1, 'Middleton': 1, 'borrows': 1, 'queen': 1, 'little': 1, 'black': 1, 'dress': 1, 'x27new': 1, 'parentsx27': 1, 'night': 1, 'Hightech': 1, 'shoes': 1, 'transform': 1, 'flats': 1, 'heels': 1, 'push': 1, 'button': 1, 'Florida': 1, 'deputies': 1, 'rescue': 1, '82yearold': 1, 'crashes': 1, 'pond': 1, 'medals': 1, 'accidentally': 1, 'donated': 1, 'Goodwill': 1, 'Terminally': 1, 'ill': 1, 'boy': 1, 'cards': 1, '14000': 1, '5yearold': 1, 'x27marriesx27': 1, 'openheart': 1, 'hero': 1, 'drives': 1, '3yearold': 1, 'survivor': 1, 'pulled': 1, 'freight': 1, 'train': 1, 'Mississippi': 1, 'QB': 1, 'Nick': 1, 'Fitzgerald': 1, 'leaves': 1, 'rivalry': 1, 'Maria': 1, 'Sharapova': 1, 'investigated': 1, 'Indian': 1, 'housing': 1, 'fraud': 1, 'Ray': 1, 'Allen': 1, 'x27catfishedx27': 1, 'throw': 1, 'disgraced': 1, 'pleads': 1, 'guilty': 1, 'Former': 1, 'Atlanta': 1, 'Braves': 1, 'GM': 1, 'John': 1, 'Coppolella': 1, 'lifetime': 1, 'baseball': 1, 'Organization': 1, 'buyout': 1, 'struggling': 1, 'tower': 1, 'Peter': 1, 'Thiel': 1, 'look': 1, 'buy': 1, 'Gawkercom': 1, 'Whirlpool': 1, 'vs': 1, 'Samsung': 1, 'LG': 1, 'trade': 1, 'tariff': 1, 'imported': 1, 'washers': 1, 'FCCx27s': 1, 'Ajit': 1, 'Pai': 1, 'touts': 1, 'decision': 1, 'Obamaera': 1, 'net': 1, 'neutrality': 1, 'rules': 1, 'hackers': 1, 'troll': 1, 'shoppers': 1, 'tips': 1, 'stay': 1, 'Fisker': 1, 'patents': 1, 'battery': 1, '500mile': 1, 'range': 1, 'minute’s': 1, 'charge': 1, 'Investing': 1, 'Stocks': 1, 'China': 1, 'focus': 1, 'selloff': 1, 'Fed': 1, 'support': 1, 'rate': 1, 'hike': 1, 'fund': 1, 'investors': 1, 'oil': 1, 'prices': 1, 'Wall': 1, 'Street': 1, 'nullify': 1, 'tech': 1, 'retreat': 1, 'advance': 1, 'trading': 1, 'slows': 1, 'Deere': 1, 'profit': 1, 'jumps': 1, '79': 1, 'fourth': 1, 'quarter': 1, '411': 1, 'Country': 1, 'Shelton': 1, 'x27fat': 1, 'uglyx27': 1, 'x27whole': 1, 'lifex27': 1, 'named': 1, 'Sexiest': 1, 'Alive': 1, 'Glen': 1, 'Campbellx27s': 1, 'daughter': 1, 'talk': 1, 'country': 1, 'iconx27s': 1, 'legacy': 1, 'Sheltonx27s': 1, 'x27Sexiest': 1, 'Alivex27': 1, 'title': 1, 'angers': 1, 'singerx27s': 1, 'past': 1, 'tweets': 1, 'Jason': 1, 'Aldean': 1, 'details': 1, 'Odd': 1, 'Manute': 1, 'Bol': 1, 'played': 1, 'Charlie': 1, 'Rose': 1, 'Roy': 1, 'continue': 1, 'person': 1, 'x27transracialx27': 1, 'identifies': 1, 'Filipino': 1, 'Jersey': 1, 'septic': 1, 'tank': 1, 'rescued': 1, 'Brooklyn': 1, 'rat': 1, 'carrying': 1, 'avocado': 1, 'subway': 1, 'mascot’s': 1, 'sounds': 1, 'male': 1, 'genitalia': 1}\n"
     ]
    }
   ],
   "source": [
    "f = request.urlopen('http://www.foxnews.com')\n",
    "source_bytes = f.read()\n",
    "source = source_bytes.decode('utf-8')\n",
    "with open('www.foxnews.com.html','w',encoding='utf8') as f:\n",
    "    f.write(source)\n",
    "a = source\n",
    "cnt=0\n",
    "cnt\n",
    "list = []\n",
    "\n",
    "\n",
    "while(cnt != len(a)) :\n",
    "    \n",
    "        if a[cnt] == '<' :\n",
    "            if(a[cnt+1] == '!' and a[cnt+2]=='-') : #주석 삭제\n",
    "                cnt+=3\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt] == '-' and a[cnt+1] == '>'):\n",
    "                        cnt+=1\n",
    "                        break\n",
    "            elif(a[cnt+1:cnt+7] == \"script\" ) : #스크립트 삭제\n",
    "                cnt+=7\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+8] == \"/script>\"):\n",
    "                        cnt+=8\n",
    "                        break\n",
    "                        \n",
    "            elif(a[cnt+1:cnt+6]) == \"style\" : ##css 삭제\n",
    "                cnt+=6\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+6]) == '/style':\n",
    "                        cnt+=6\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    \n",
    "            else:\n",
    "                while(a[cnt] != '>'): #HTML 삭제\n",
    "                    cnt+=1\n",
    "                    \n",
    "        \n",
    "        elif  a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt]!=' ' and a[cnt] !='\\n' :\n",
    "            start = cnt\n",
    "            while a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt] !=' ' and a[cnt] !='\\n' :\n",
    "                    cnt+=1\n",
    "                    if(cnt==len(a)):\n",
    "                            break\n",
    "                        \n",
    "            end = cnt\n",
    "            list.append(a[start:end])\n",
    "            \n",
    "        else :\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "c=[]\n",
    "for x in string.punctuation: #구두문자 리스트화\n",
    "    c.append(x)\n",
    "c.append(\"\\r\")\n",
    "c.append(\"nbsp\")\n",
    "c.append(\"raquo\")\n",
    "\n",
    "for x in range(len(list)) : #구두문자가 list의 원소안에 포함되어있을 경우\n",
    "    for k in c:\n",
    "        if k in list[x]:\n",
    "            list[x] = list[x].replace(k,'') #구두문자를 없앤다\n",
    "    \n",
    "\n",
    "list.remove('') #구두문자만 있었을 경우 공백만 남으므로 공백 없애줌\n",
    "            \n",
    "dic = dict()\n",
    "for x in list:\n",
    "    if x not in dic.keys(): #list의 원소가 사전에 없으면 추가\n",
    "        dic[x] = 1\n",
    "    elif x in dic.keys(): #이미 있는 원소면 1추가\n",
    "        dic[x] += 1\n",
    "        \n",
    "f = open(\"StopwordList.txt\",\"r\")\n",
    "stopword = f.readlines()\n",
    "stopword_title = []\n",
    "for i in range(len(stopword)):\n",
    "    stopword[i] = stopword[i][:-1]\n",
    "for i in range(len(stopword)):\n",
    "    stopword_title.append(stopword[i].title())\n",
    "\n",
    "dict_key_list = []\n",
    "for i in dic.keys():\n",
    "    dict_key_list.append(i)\n",
    "for ele in stopword :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "for ele in stopword_title :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "while '' in dic.keys():\n",
    "    del dic['']\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key = lambda x : x[1], reverse = True)\n",
    "url_frequency = \"www.foxnews.com.words.frequency\"\n",
    "with open(url_frequency,\"wb\") as f:\n",
    "    pickle.dump(dict(dic_sorted), f)\n",
    "    \n",
    "with open(url_frequency,\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHRON (http://www.chron.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Houston': 28, 'Black': 26, 'Friday': 26, 'Thanksgiving': 24, 'Texas': 21, 'ad': 19, 'Harvey': 12, 'Gifts': 10, 'News': 8, 'Sports': 8, '2017': 8, 'accused': 7, 'College': 7, 'football': 7, 'holiday': 7, 'WYFF': 7, 'Business': 6, 'Chronicle': 6, 'shot': 6, 'Weather': 6, 'Top': 6, 'Trump': 6, 'head': 5, 'helps': 5, 'woman': 5, 'military': 5, 'Rockets': 5, 'win': 5, '100': 5, 'home': 5, 'Holiday': 5, 'Policy': 4, 'Archives': 4, 'Manhunt': 4, 'underway': 4, 'trooper': 4, 'gunned': 4, 'found': 4, 'Politics': 4, 'Supreme': 4, 'Court': 4, 'death': 4, 'capital': 4, 'punishment': 4, 'catch': 4, 'mailing': 4, 'bomb': 4, 'US': 4, 'Texans': 4, 'Philip': 4, 'Rivers': 4, 'Chargers': 4, 'beat': 4, 'fading': 4, 'Cowboys': 4, 'time': 4, 'Car': 4, 'People': 4, 'hilarious': 4, 'memes': 4, 'Day': 4, 'police': 4, '7': 4, '11': 4, 'following': 4, 'Remembering': 4, 'Cabbage': 4, 'Patch': 4, 'craze': 4, 'radio': 4, 'Kingwood': 4, 'HoustonChroniclecom': 4, 'Chron': 3, 'Careers': 3, 'Privacy': 3, 'thousands': 3, 'Third': 3, 'Ward': 3, 'driveby': 3, 'gas': 3, 'Hurricane': 3, 'Editorials': 3, 'Nick': 3, 'knell': 3, 'Cat': 3, 'hair': 3, 'World': 3, 'Museum': 3, 'Astros': 3, 'Nation': 3, 'Buy': 3, 'Gear': 3, 'preview': 3, 'Real': 3, 'Estate': 3, 'search': 3, 'hot': 3, 'Search': 3, '6': 3, 'TX': 3, 'Houstonarea': 3, 'Backstreet': 3, 'Boys': 3, 'singer': 3, 'rape': 3, 'MS13': 3, 'stab': 3, 'times': 3, 'majors': 3, 'unemployment': 3, 'fire': 3, 'chase': 3, 'Trending': 3, '2': 3, 'sharing': 3, 'theyre': 3, 'Lowes': 3, 'credits': 3, 'troops': 3, 'advances': 3, 'NFL': 3, 'local': 3, 'Insurer': 3, 'resort': 3, 'sufficient': 3, 'funding': 3, 'displaced': 3, 'record': 3, 'Amazon': 3, 'FoxLA': 3, 'Fox10Phoenix': 3, 'Fox4': 3, 'played': 3, 'Spring': 3, 'Friendswood': 3, 'Entertainment': 2, 'Sign': 2, 'Home': 2, 'Contact': 2, 'Advertise': 2, 'Ad': 2, 'Terms': 2, 'Subscribe': 2, 'Parade': 2, 'draws': 2, 'kickoff': 2, 'Valero': 2, 'station': 2, 'eye': 2, 'hand': 2, 'Opinions': 2, 'La': 2, 'Houstons': 2, 'History': 2, 'Gov': 2, 'critical': 2, 'crashing': 2, 'motorcycle': 2, 'look': 2, 'million': 2, 'assault': 2, 'giving': 2, 'John': 2, 'McClains': 2, 'Week': 2, '12': 2, 'predictions': 2, 'vs': 2, 'Navy': 2, 'Thunder': 2, 'firepower': 2, 'signature': 2, 'Sponsored': 2, 'Content': 2, 'workers': 2, 'business': 2, 'Movies': 2, 'Slay': 2, 'bells': 2, 'ringing': 2, 'Beyoncés': 2, 'merch': 2, 'Timing': 2, 'Gilroys': 2, 'Roman': 2, 'Israel': 2, 'Esq': 2, 'Coco': 2, 'run': 2, 'PixarDisney': 2, 'Life': 2, 'List': 2, 'parade': 2, 'Christmas': 2, 'Carol': 2, 'Career': 2, 'jobs': 2, '2016': 2, 'Auto': 2, 'house': 2, 'pleads': 2, 'guilty': 2, 'girls': 2, 'watch': 2, 'weekend': 2, 'restaurants': 2, 'Pinterest': 2, 'videos': 2, 'Mattress': 2, 'Mack': 2, 'dog': 2, 'crashes': 2, 'share': 2, 'Deals': 2, 'Bargains': 2, 'Spoil': 2, 'Costing': 2, 'Fortune': 2, 'FourLegged': 2, 'Friend': 2, 'Popular': 2, '1': 2, 'Carter': 2, '3': 2, '4': 2, '5': 2, 'Police': 2, 'Maryland': 2, 'Map': 2, 'compares': 2, 'countries': 2, 'releases': 2, '8': 2, '9': 2, '10': 2, 'Stay': 2, 'Connected': 2, 'HS': 2, 'primer': 2, 'Arearound': 2, 'playoffs': 2, 'talk': 2, 'host': 2, 'Lance': 2, 'Zierlein': 2, 'return': 2, 'Former': 2, 'QB': 2, 'Sean': 2, 'Salisbury': 2, 'drop': 2, 'Smith': 2, 'coach': 2, 'Mike': 2, 'DAntoni': 2, 'Memes': 2, 'fun': 2, 'Bills': 2, 'celebrate': 2, 'JOBS': 2, 'Zippia': 2, 'rank': 2, 'Aftermath': 2, 'Northwest': 2, 'Harris': 2, 'YMCA': 2, 'rebuilding': 2, 'couple': 2, 'raises': 2, 'Huffman': 2, 'Strong': 2, 'event': 2, 'commends': 2, 'communitys': 2, 'heroism': 2, 'throughout': 2, 'Giant': 2, 'beehive': 2, 'walls': 2, '20': 2, 'ZIP': 2, 'codes': 2, 'FEMA': 2, 'assistance': 2, 'applications': 2, 'highlight': 2, 'Foundation': 2, 'donates': 2, 'books': 2, 'children': 2, 'impacted': 2, 'Huricane': 2, 'Macys': 2, 'Toys': 2, 'Sams': 2, 'Club': 2, 'Sears': 2, 'Costco': 2, 'Playing': 2, 'meal': 2, 'leads': 2, 'Fort': 2, 'Exclusively': 2, 'homes': 2, 'school': 2, 'injured': 2, 'service': 2, 'Katy': 2, 'Lone': 2, 'Star': 2, 'Flight': 2, 'announces': 2, 'warbird': 2, 'nicknamed': 2, '—': 2, 'events': 2, 'arcade': 2, 'games': 2, 'kid': 2, 'MUD': 2, '386': 2, 'Officials': 2, 'partner': 2, 'entities': 2, 'Sugar': 2, 'Land': 2, 'residents': 2, 'Humble': 2, 'Hearst': 2, 'Newspapers': 2, 'Chroncom': 1, 'November': 1, '23': 1, 'Updated': 1, '809PM': 1, 'CST': 1, 'SUBSCRIBE': 1, 'low': 1, '1week': 1, 'Classified': 1, 'Niche': 1, 'Publication': 1, 'Ads': 1, 'Shop': 1, 'Newsletters': 1, 'HC': 1, 'Local': 1, 'Neighborhoods': 1, 'Traffic': 1, 'Radar': 1, 'Forecasts': 1, 'Severe': 1, 'Guide': 1, 'Education': 1, 'Investigates': 1, 'Obituaries': 1, 'Staff': 1, 'Reader': 1, 'Blogs': 1, 'Classifieds': 1, 'Columnists': 1, 'Opinion': 1, 'Letters': 1, 'Editor': 1, 'Outlook': 1, 'Anderson': 1, 'Cartoons': 1, 'Voz': 1, 'Espa241ol': 1, 'condition': 1, 'Hummer': 1, 'Crime': 1, 'Americas': 1, 'Science': 1, 'Environment': 1, 'Strange': 1, 'Weird': 1, 'Videos': 1, 'inside': 1, '500': 1, 'Bible': 1, 'Social': 1, 'media': 1, 'reacts': 1, 'Sen': 1, 'Al': 1, 'Frankens': 1, 'alleged': 1, 'sexual': 1, 'Photos': 1, 'coup': 1, 'Zimbabwe': 1, 'looks': 1, 'Maine': 1, 'viral': 1, 'image': 1, 'uterus': 1, 'middle': 1, 'finger': 1, 'Dynamo': 1, 'School': 1, 'Colleges': 1, 'UH': 1, 'Rice': 1, 'UT': 1, 'AM': 1, 'Outdoors': 1, 'Tickets': 1, 'Fan': 1, 'Energy': 1, 'Fuel': 1, 'Fix': 1, 'Technology': 1, 'Money': 1, 'Tips': 1, 'Insider': 1, 'Press': 1, 'Releases': 1, 'Mgmt': 1, 'Workplaces': 1, 'Legal': 1, 'Notices': 1, 'Directory': 1, 'Venezuelan': 1, 'president': 1, 'appoints': 1, 'Citgo': 1, 'Information': 1, 'technology': 1, 'firms': 1, 'faced': 1, 'shortage': 1, 'Macron': 1, 'effect': 1, 'fuels': 1, 'Paris': 1, 'bid': 1, 'postBrexit': 1, 'Tribal': 1, 'leaders': 1, 'aim': 1, 'oil': 1, 'development': 1, 'Restaurants': 1, 'Bars': 1, 'Music': 1, 'TV': 1, 'Arts': 1, 'Theater': 1, 'Horoscopes': 1, 'Books': 1, 'Puzzles': 1, 'Games': 1, 'Drink': 1, 'Beginners': 1, 'Luck': 1, 'cocktail': 1, 'Pass': 1, 'Provisions': 1, 'Society': 1, 'Travel': 1, 'Style': 1, 'Food': 1, 'Cooking': 1, 'Health': 1, 'Escapes': 1, 'Luxe': 1, 'Weddings': 1, 'Product': 1, 'Reviews': 1, 'Live': 1, 'Healthy': 1, 'McDormand': 1, 'Rockwell': 1, 'explode': 1, 'Billboards': 1, 'Outside': 1, 'Ebbing': 1, 'Girl': 1, 'Scouts': 1, 'Dont': 1, 'daughter': 1, 'hug': 1, 'people': 1, 'Whataburger': 1, 'makes': 1, 'Jobs': 1, 'Advanced': 1, 'Browse': 1, 'job': 1, 'categories': 1, 'Salary': 1, 'Wizard': 1, 'Rescue': 1, 'Engineering': 1, 'Salute': 1, 'Nurses': 1, 'Advice': 1, 'Post': 1, 'Job': 1, 'dream': 1, 'opportunity': 1, 'nightmare': 1, '25': 1, 'pay': 1, '100K': 1, 'Set': 1, 'career': 1, 'goal': 1, 'month': 1, 'highestpaying': 1, 'entrylevel': 1, 'Cars': 1, 'Certified': 1, 'Dealers': 1, 'Lincoln': 1, 'Navigator': 1, 'concept': 1, 'legit': 1, 'quit': 1, 'Hennessey': 1, 'pushes': 1, 'Camaro': 1, '200': 1, 'MPH': 1, 'Riding': 1, 'Indian': 1, 'Chieftain': 1, 'BMW': 1, 'Price': 1, 'Survey': 1, 'Farms': 1, 'Ranches': 1, 'Senior': 1, 'Living': 1, 'Perfect': 1, 'Houseton': 1, 'Dallas': 1, 'living': 1, 'pool': 1, 'headed': 1, 'auction': 1, 'Builder': 1, 'debut': 1, 'clubhouse': 1, '55andup': 1, 'community': 1, 'Annual': 1, 'salary': 1, 'buy': 1, 'Menu': 1, 'Sections': 1, 'Happening': 1, 'nabbed': 1, 'beating': 1, 'homeless': 1, 'camp': 1, 'Olympic': 1, 'gymnastics': 1, 'exdoc': 1, '125': 1, 'Congressman': 1, 'apologizes': 1, 'nude': 1, 'photo': 1, 'Abbott': 1, 'late': 1, 'Cockroaches': 1, 'slime': 1, 'plague': 1, 'Cops': 1, 'decapitate': 1, 'kill': 1, '602PM': 1, 'Cafe': 1, 'criticized': 1, 'sign': 1, 'saying': 1, 'happily': 1, 'gentrifying': 1, 'Musttry': 1, 'recipes': 1, 'according': 1, 'Throwback': 1, 'Theres': 1, 'possibly': 1, 'infected': 1, 'rabies': 1, 'lost': 1, 'mail': 1, 'Sound': 1, 'expert': 1, 'arent': 1, 'star': 1, 'selling': 1, '35': 1, 'mansion': 1, 'Report': 1, 'uptick': 1, '701PM': 1, 'Stores': 1, 'hours': 1, 'MORE': 1, 'HOUSTON': 1, 'AND': 1, 'TEXAS': 1, 'NEWS': 1, 'Remember': 1, 'Marines': 1, 'toughest': 1, 'battles': 1, 'reacted': 1, 'War': 1, 'II': 1, 'WWII': 1, 'veteran': 1, 'dubbed': 1, 'Shipyard': 1, 'Tarzan': 1, 'Notorious': 1, 'highway': 1, 'speed': 1, 'traps': 1, 'eat': 1, 'road': 1, 'trip': 1, 'updated': 1, 'ultimate': 1, 'experiences': 1, 'visitors': 1, 'Companies': 1, 'hiring': 1, 'seasonal': 1, 'paid': 1, '60000': 1, 'live': 1, 'Cancun': 1, 'Shooter': 1, 'backyard': 1, 'BBQ': 1, 'SW': 1, 'Stolen': 1, 'vehicle': 1, 'sparks': 1, 'morning': 1, 'BE': 1, 'SOMEONE': 1, 'graffiti': 1, 'stunning': 1, 'light': 1, 'senior': 1, 'killed': 1, 'town': 1, 'homicide': 1, '17': 1, 'Shopping': 1, 'Target': 1, 'Walmart': 1, 'Kohls': 1, 'deals': 1, 'Video': 1, 'Pink': 1, 'Taco': 1, 'restaurant': 1, 'hosts': 1, 'fortunate': 1, 'HELPING': 1, 'THOSE': 1, 'IN': 1, 'NEED': 1, '1000': 1, 'received': 1, 'begins': 1, 'heat': 1, 'SoCal': 1, 'Gallery': 1, 'Furniture': 1, 'doors': 1, 'feed': 1, 'folks': 1, 'KRIV': 1, 'Chris': 1, 'Justuss': 1, 'Complete': 1, 'Forecast': 1, '5PM': 1, '11232017': 1, 'ramp': 1, 'interstate': 1, 'aims': 1, 'ease': 1, 'shopping': 1, 'traffic': 1, 'START': 1, 'YOUR': 1, 'ENGINES': 1, 'Arizona': 1, 'International': 1, 'kicks': 1, 'Downtown': 1, 'Phoenix': 1, 'Salvation': 1, 'Army': 1, 'serves': 1, 'officer': 1, 'authorities': 1, 'Upstate': 1, 'counties': 1, 'Geoff': 1, 'Hart': 1, 'Allyson': 1, 'Powell': 1, 'ice': 1, 'skating': 1, 'lessons': 1, 'Convention': 1, 'Center': 1, 'Fox35Orlando': 1, 'Golden': 1, 'Apple': 1, 'Teresa': 1, 'Garrett': 1, 'Grace': 1, 'gratitude': 1, 'Fox5': 1, 'Spartanburg': 1, 'Soup': 1, 'Kitchen': 1, 'hundreds': 1, 'Delay': 1, 'Teacher': 1, 'Retirement': 1, 'System': 1, 'checks': 1, 'steals': 1, 'Worth': 1, 'Fire': 1, 'SUV': 1, '112317': 1, 'PM': 1, 'Samaritan': 1, 'hitandrun': 1, 'driver': 1, 'Tens': 1, 'wait': 1, 'Creech': 1, 'McCullers': 1, 'passion': 1, 'helping': 1, 'pets': 1, 'via': 1, 'rescue': 1, 'laborers': 1, 'suffer': 1, 'wage': 1, 'theft': 1, 'postHarvey': 1, 'reconstruction': 1, 'Onlines': 1, 'retail': 1, 'sales': 1, 'grows': 1, 'larger': 1, 'Listen': 1, 'architect': 1, 'tells': 1, 'clients': 1, 'futureproof': 1, 'buildings': 1, 'Grieder': 1, 'Donald': 1, 'valid': 1, 'Bayou': 1, 'City': 1, 'David': 1, 'Cassidy': 1, 'rodeo': 1, 'subscriber': 1, 'read': 1, 'stories': 1, '547PM': 1, '633PM': 1, 'Tech': 1, '3pointers': 1, 'Takeaways': 1, '12595': 1, 'Ten': 1, 'unforgettable': 1, 'moments': 1, 'Thanksgivings': 1, 'past': 1, '625PM': 1, 'Keenum': 1, 'Vikings': 1, 'hold': 1, 'Lions': 1, 'lock': 1, 'NFC': 1, 'North': 1, 'Stage': 1, 'set': 1, 'epic': 1, 'playoff': 1, 'rematches': 1, 'players': 1, 'day': 1, 'AE': 1, 'Looking': 1, 'Nov': 1, '24': 1, 'Instafamous': 1, 'Meet': 1, 'Hotel': 1, 'Alessandra': 1, 'Fiance': 1, 'refuses': 1, 'vacate': 1, 'White': 1, 'House': 1, 'talks': 1, 'weapons': 1, 'Coast': 1, 'Guard': 1, 'ProRoy': 1, 'Moore': 1, 'fundraises': 1, 'Trumps': 1, 'near': 1, 'endorsement': 1, 'verdict': 1, 'San': 1, 'Francisco': 1, 'pier': 1, 'killing': 1, 'jury': 1, 'breaks': 1, 'Pence': 1, 'visits': 1, 'hospital': 1, 'AP': 1, 'Assassination': 1, 'President': 1, 'Kennedy': 1, 'BizFeed': 1, 'investment': 1, 'agent': 1, 'pays': 1, '3000': 1, 'fine': 1, 'Kroger': 1, 'expands': 1, 'grocery': 1, 'delivery': 1, 'attorneys': 1, 'bash': 1, 'plan': 1, 'hike': 1, 'national': 1, 'park': 1, 'fees': 1, 'goes': 1, 'holidays': 1, 'magnified': 1, 'store': 1, 'presence': 1, 'research': 1, 'invest': 1, 'instead': 1, 'Homes': 1, 'apartment': 1, 'rents': 1, 'rebound': 1, 'Salem': 1, 'Lutheran': 1, 'Church': 1, 'takes': 1, 'BJ': 1, 'Services': 1, 'Tomball': 1, 'popular': 1, 'top': 1, 'global': 1, 'cities': 1, 'raise': 1, 'family': 1, 'Volunteers': 1, 'sought': 1, 'ClotheAChild': 1, 'Atascocita': 1, 'Crosby': 1, 'Websterarea': 1, 'building': 1, 'CyFair': 1, 'employees': 1, 'speak': 1, '14yearold': 1, 'stolen': 1, 'car': 1, 'Teen': 1, 'forget': 1, 'getting': 1, 'Altuves': 1, 'autograph': 1, 'Bend': 1, 'child': 1, 'pornography': 1, 'charges': 1, 'sent': 1, 'explicit': 1, 'photos': 1, 'underage': 1, 'girl': 1, 'Convicted': 1, 'killer': 1, 'speaks': 1, 'jailhouse': 1, 'interview': 1, 'Woodlands': 1, 'owner': 1, 'dies': 1, 'survives': 1, 'weeks': 1, 'rescued': 1, 'Pearland': 1, 'Alvin': 1, 'Lakes': 1, 'Savannah': 1, 'upset': 1, 'lack': 1, 'EMS': 1, 'HISD': 1, 'students': 1, 'en': 1, 'route': 1, 'Pearl': 1, 'Theaters': 1, 'Antony': 1, 'Cleopatra': 1, 'explores': 1, 'original': 1, 'ISD': 1, 'highlights': 1, 'energy': 1, 'efficiency': 1, 'AVID': 1, 'program': 1, 'resources': 1, 'Citizen': 1, 'revealed': 1, 'Lake': 1, 'businesses': 1, 'continue': 1, 'reopen': 1, 'Bay': 1, 'Mountains': 1, 'debris': 1, 'removed': 1, 'Porte': 1, 'seize': 1, 'meth': 1, 'crack': 1, 'narcotic': 1, 'bust': 1, 'choice': 1, 'Logo': 1, 'Return': 1, 'Company': 1, 'Choices': 1, 'amp': 1, 'Conditions': 1, 'California': 1, 'Rights': 1, 'Customer': 1, 'Service': 1, 'Newsroom': 1, 'Contacts': 1, 'Connect': 1, 'Email': 1, 'Newsletter': 1, 'Facebook': 1, 'Twitter': 1, 'Google': 1, 'Instagram': 1, 'iPad': 1, 'app': 1, 'eEdition': 1, 'Demo': 1, 'Todays': 1, 'eNewspaper': 1, '©': 1, 'Copyright': 1, 'LLC': 1}\n"
     ]
    }
   ],
   "source": [
    "f = request.urlopen('http://www.chron.com')\n",
    "source_bytes = f.read()\n",
    "source = source_bytes.decode('utf-8')\n",
    "with open(\"www.chron.com.html\",'w',encoding='utf8') as f:\n",
    "    f.write(source)\n",
    "a = source\n",
    "cnt=0\n",
    "cnt\n",
    "list = []\n",
    "\n",
    "\n",
    "while(cnt != len(a)) :\n",
    "    \n",
    "        if a[cnt] == '<' :\n",
    "            if(a[cnt+1] == '!' and a[cnt+2]=='-') : #주석 삭제\n",
    "                cnt+=3\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt] == '-' and a[cnt+1] == '>'):\n",
    "                        cnt+=1\n",
    "                        break\n",
    "            elif(a[cnt+1:cnt+7] == \"script\" ) : #스크립트 삭제\n",
    "                cnt+=7\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+8] == \"/script>\"):\n",
    "                        cnt+=8\n",
    "                        break\n",
    "                        \n",
    "            elif(a[cnt+1:cnt+6]) == \"style\" : ##css 삭제\n",
    "                cnt+=6\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+6]) == '/style':\n",
    "                        cnt+=6\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    \n",
    "            else:\n",
    "                while(a[cnt] != '>'): #HTML 삭제\n",
    "                    cnt+=1\n",
    "                    \n",
    "        \n",
    "        elif  a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt]!=' ' and a[cnt] !='\\n' :\n",
    "            start = cnt\n",
    "            while a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt] !=' ' and a[cnt] !='\\n' :\n",
    "                    cnt+=1\n",
    "                    if(cnt==len(a)):\n",
    "                            break\n",
    "                        \n",
    "            end = cnt\n",
    "            list.append(a[start:end])\n",
    "            \n",
    "        else :\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "c=[]\n",
    "for x in string.punctuation: #구두문자 리스트화\n",
    "    c.append(x)\n",
    "c.append(\"\\r\")\n",
    "c.append(\"nbsp\")\n",
    "c.append(\"raquo\")\n",
    "\n",
    "for x in range(len(list)) : #구두문자가 list의 원소안에 포함되어있을 경우\n",
    "    for k in c:\n",
    "        if k in list[x]:\n",
    "            list[x] = list[x].replace(k,'') #구두문자를 없앤다\n",
    "    \n",
    "\n",
    "list.remove('') #구두문자만 있었을 경우 공백만 남으므로 공백 없애줌\n",
    "            \n",
    "dic = dict()\n",
    "for x in list:\n",
    "    if x not in dic.keys(): #list의 원소가 사전에 없으면 추가\n",
    "        dic[x] = 1\n",
    "    elif x in dic.keys(): #이미 있는 원소면 1추가\n",
    "        dic[x] += 1\n",
    "        \n",
    "f = open(\"StopwordList.txt\",\"r\")\n",
    "stopword = f.readlines()\n",
    "stopword_title = []\n",
    "for i in range(len(stopword)):\n",
    "    stopword[i] = stopword[i][:-1]\n",
    "for i in range(len(stopword)):\n",
    "    stopword_title.append(stopword[i].title())\n",
    "\n",
    "dict_key_list = []\n",
    "for i in dic.keys():\n",
    "    dict_key_list.append(i)\n",
    "for ele in stopword :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "for ele in stopword_title :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "while '' in dic.keys():\n",
    "    del dic['']\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key = lambda x : x[1], reverse = True)\n",
    "url_frequency = \"www.chron.com.words.frequency\"\n",
    "with open(url_frequency,\"wb\") as f:\n",
    "    pickle.dump(dict(dic_sorted), f)\n",
    "    \n",
    "with open(url_frequency,\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAtimes(http://www.latimes.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'32': 36, 'Thanksgiving': 13, 'LA': 10, 'read': 5, 'officers': 5, 'driverless': 4, 'US': 4, 'Trump': 4, 'grateful': 4, 'News': 3, 'California': 3, 'tax': 3, 'despite': 3, 'Washington': 3, 'military': 3, 'status': 3, '—': 3, 'survived': 3, 'Hurricanes': 3, 'Harvey': 3, 'Irma': 3, 'Maria': 3, 'Asian': 3, 'Los': 2, 'Angeles': 2, 'Times': 2, 'Dish': 2, 'Politics': 2, 'GOP': 2, 'plan': 2, 'missing': 2, 'submarine': 2, 'Rivers': 2, '286': 2, 'rout': 2, 'Cowboys': 2, 'Despite': 2, 'CALIFORNIA': 2, 'rare': 2, 'plant': 2, 'renegade': 2, 'environmental': 2, 'activist': 2, 'derail': 2, 'Ballona': 2, 'Wetlands': 2, 'restoration': 2, 'Roy': 2, 'campaign': 2, 'sexual': 2, 'denies': 2, 'neutrality': 2, 'FCC': 2, 'Michigan': 2, 'John': 2, 'competition': 2, 'plans': 2, 'immigrants': 2, 'Opinion': 2, 'canapost': 2, 'argument': 2, 'COMPANY': 2, 'TOWN': 2, 'leave': 2, 'road': 2, 'spent': 2, '39': 2, 'bars': 2, 'murders': 2, 'didnapost': 2, 'commit': 2, 'Gov': 2, 'Jerry': 2, 'Brown': 2, 'pardoned': 2, 'afford': 2, 'Entertainment': 2, 'MUSIC': 2, 'thanks': 2, 'holiday': 2, 'found': 2, 'Chargers': 2, 'People': 2, 'family': 2, 'revolution': 2, 'crashes': 2, 'Turkey': 2, 'NY': 2, 'North': 2, '2': 2, 'World': 2, 'South': 2, 'Korean': 2, 'killed': 2, 'police': 2, 'American': 2, 'allege': 2, 'racial': 2, 'discrimination': 2, 'San': 2, 'Gabriel': 2, 'Police': 2, 'nation': 1, 'world': 1, 'Daily': 1, 'turkey': 1, 'cook': 1, 'Answers': 1, 'lastminute': 1, 'questions': 1, 'latimescom': 1, 'Republicans': 1, 'push': 1, 'hard': 1, 'voters': 1, 'arenapost': 1, 'Lisa': 1, 'Mascaro': 1, 'Americans': 1, 'view': 1, 'mainly': 1, 'helping': 1, 'corporations': 1, 'rich': 1, 'polls': 1, 'Outside': 1, 'analyses': 1, '15trillion': 1, 'package': 1, 'echo': 1, 'assessments': 1, 'revisions': 1, 'Mexico': 1, 'Americas': 1, 'Argentina': 1, 'suffered': 1, 'explosion': 1, 'doesnapost': 1, 'crewaposs': 1, 'fate': 1, 'CHARGERS': 1, 'Philip': 1, 'fine': 1, 'form': 1, 'Chargersapos': 1, 'Downtown': 1, 'records': 1, 'hottest': 1, '1877': 1, 'NATION': 1, 'accident': 1, 'hundreds': 1, 'willing': 1, 'gamble': 1, 'riding': 1, 'shuttle': 1, 'Las': 1, 'Vegas': 1, 'Moores': 1, 'Senate': 1, 'train': 1, 'wreck': 1, 'decent': 1, 'shot': 1, 'winning': 1, 'declares': 1, 'Myanmar': 1, 'ethnic': 1, 'cleansing': 1, 'Moore': 1, 'alleged': 1, 'misconduct': 1, 'Net': 1, 'rules': 1, 'targeted': 1, 'repeal': 1, 'chairman': 1, 'Rep': 1, 'Conyers': 1, 'harassment': 1, 'settlements': 1, 'tough': 1, 'battle': 1, 'proving': 1, 'ATT': 1, 'Time': 1, 'Warner': 1, 'squeeze': 1, 'administration': 1, 'protected': 1, '60000': 1, 'Haitian': 1, 'Editorial': 1, 'win': 1, 'crazy': 1, 'score': 1, 'table': 1, 'comebacks': 1, 'Macyaposs': 1, 'Day': 1, 'Parade': 1, 'York': 1, 'Lasseter': 1, 'takes': 1, 'Disney': 1, 'Pixar': 1, 'uncertain': 1, 'ahead': 1, 'OPINIONS': 1, 'MORE': 1, 'COMMENTARY': 1, 'tradition': 1, 'Itaposs': 1, 'lie': 1, 'Dying': 1, 'live': 1, 'Bundys': 1, 'poster': 1, 'boys': 1, 'Americaaposs': 1, 'ruralurban': 1, 'divide': 1, 'Unified': 1, 'lurch': 1, 'financial': 1, 'crisis': 1, 'Iaposm': 1, 'Please': 1, 'stop': 1, 'killing': 1, 'net': 1, 'chained': 1, 'CPI': 1, 'secret': 1, 'hike': 1, 'middle': 1, 'class': 1, 'slipped': 1, 'bills': 1, 'Giving': 1, 'music': 1, 'redeemed': 1, '2017': 1, 'Music': 1, 'mood': 1, 'MOVIES': 1, '‘Disaster': 1, 'Artistaposs’': 1, 'James': 1, 'Franco': 1, 'art': 1, 'heart': 1, '‘The': 1, 'Room’': 1, '‘Citizen': 1, 'Kane’': 1, 'bad': 1, 'movies': 1, 'CBS': 1, 'quick': 1, 'resolution': 1, 'dispute': 1, 'prevent': 1, 'millions': 1, 'watching': 1, 'game': 1, 'TELEVISION': 1, 'Spike': 1, 'Leeaposs': 1, 'aposSheaposs': 1, 'Gotta': 1, 'Itapos': 1, 'reboot': 1, 'strong': 1, 'TV': 1, 'women': 1, 'helped': 1, 'ENTERTAINMENT': 1, 'aposYoung': 1, 'Charlieapos': 1, 'podcast': 1, 'explores': 1, 'Manson': 1, 'kid': 1, 'murderer': 1, 'National': 1, 'Life': 1, 'water': 1, 'Hurricane': 1, 'survivors': 1, 'theyaposre': 1, 'Molly': 1, 'HennessyFiske': 1, 'Milton': 1, 'Carrero': 1, 'Galarza': 1, 'heartache': 1, 'devastation': 1, 'people': 1, 'comes': 1, 'week': 1, 'official': 1, 'close': 1, 'Nov': 1, '30': 1, 'destructive': 1, 'hurricane': 1, 'seasons': 1, 'America': 1, 'time': 1, 'fightin': 1, 'word': 1, 'Slain': 1, 'Baltimore': 1, 'detective': 1, 'testify': 1, 'indicted': 1, '18': 1, 'months': 1, 'Haitians': 1, 'granted': 1, 'special': 1, 'shocked': 1, 'disappointed': 1, 'relieved': 1, 'Border': 1, 'Patrol': 1, 'agent': 1, 'beaten': 1, 'death': 1, 'Texas': 1, 'fall': 1, 'FBI': 1, 'exact': 1, 'political': 1, 'price': 1, 'race': 1, 'embrace': 1, 'vehicles': 1, 'cleared': 1, 'regulatory': 1, 'hurdles': 1, 'auto': 1, 'companies': 1, 'brushed': 1, 'aside': 1, 'consumer': 1, 'warnings': 1, 'risk': 1, 'hacking': 1, 'recent': 1, 'hearing': 1, 'lawmakers': 1, 'absorbed': 1, 'economic': 1, 'illustrated': 1, 'Ousted': 1, 'Russian': 1, 'contacts': 1, 'exnational': 1, 'security': 1, 'advisor': 1, 'scrutiny': 1, 'ties': 1, 'OK': 1, 'mention': 1, 'personaposs': 1, 'immigration': 1, 'court': 1, 'NAACP': 1, 'save': 1, 'viral': 1, 'protests': 1, 'leadership': 1, 'storied': 1, 'tries': 1, 'reinvent': 1, 'Nebraska': 1, 'regulators': 1, 'approved': 1, 'route': 1, 'Keystone': 1, 'XL': 1, 'pipeline': 1, 'built': 1, 'wires': 1, 'mom': 1, 'charged': 1, 'driving': 1, 'crashing': 1, 'kids': 1, 'car': 1, 'Sound': 1, 'heard': 1, 'Argentine': 1, 'sub': 1, 'search': 1, 'aposexplosionapos': 1, 'beat': 1, 'fading': 1, 'Honduras': 1, 'president': 1, 'seeks': 1, '2nd': 1, 'term': 1, 'constitutional': 1, 'ban': 1, 'credits': 1, 'troops': 1, 'advances': 1, 'finalizes': 1, 'upgrade': 1, '3': 1, 'Adirondack': 1, 'campgrounds': 1, 'Maye': 1, 'leads': 1, '9': 1, 'Carolina': 1, '10278': 1, 'Portland': 1, 'Shoppers': 1, 'mobilize': 1, 'retailers': 1, 'branch': 1, 'ExRep': 1, 'Hinchey': 1, 'pushed': 1, 'protect': 1, 'environment': 1, 'dies': 1, 'Fire': 1, 'engulfs': 1, 'homes': 1, 'injuries': 1, 'reported': 1, 'donapost': 1, 'Argentinaaposs': 1, 'Genocide': 1, 'conviction': 1, 'exBosnian': 1, 'Serb': 1, 'commander': 1, 'Ratko': 1, 'Mladic': 1, 'fuels': 1, 'hopes': 1, 'future': 1, 'accountability': 1, 'remains': 1, 'unclear': 1, 'Lebanon': 1, 'Prime': 1, 'Minister': 1, 'Saad': 1, 'Hariri': 1, 'suspends': 1, 'resignation': 1, 'presidentaposs': 1, 'request': 1, 'cyclingobsessed': 1, 'Colombia': 1, 'dreamed': 1, 'glory': 1, 'bike': 1, 'Steven': 1, 'Motavita': 1, '13': 1, 'bought': 1, 'mountain': 1, 'bicycle': 1, 'compete': 1, 'local': 1, 'races': 1, 'cheap': 1, 'heavy': 1, 'aluminum': 1, 'frame': 1, 'fat': 1, 'tires': 1, 'unsuited': 1, 'money': 1, 'harvesting': 1, 'potatoes': 1, 'uncles': 1, 'shared': 1, 'cycling': 1, '11': 1, 'human': 1, 'rights': 1, 'activists': 1, 'trial': 1, 'wandering': 1, 'near': 1, 'DMZ': 1, 'deported': 1, 'officials': 1, 'confirm': 1, 'Watch': 1, 'dramatic': 1, 'video': 1, 'forces': 1, 'chasing': 1, 'firing': 1, 'defecting': 1, 'soldier': 1, 'Russiaaposs': 1, 'role': 1, 'Syria': 1, 'nearing': 1, 'Putin': 1, 'meeting': 1, 'Assad': 1, 'Generations': 1, 'friends': 1, 'woman': 1, 'generosity': 1, 'male': 1, 'suspects': 1, 'collision': 1, 'Orange': 1, 'County': 1, 'sheriffaposs': 1, 'deputies': 1, 'chase': 1, '18yearold': 1, 'coworkeraposs': 1, 'jealous': 1, 'boyfriend': 1, 'lawsuit': 1, 'PD': 1, 'Five': 1, 'suing': 1, 'Department': 1, 'alleging': 1, 'subjected': 1, 'widespread': 1, 'hostile': 1, 'culture': 1, 'managers': 1, 'slurs': 1, 'refused': 1, 'hire': 1, 'promote': 1, 'passed': 1, 'help': 1, 'homeless': 1, 'aposWe': 1, 'havenapost': 1, 'seen': 1, 'Depressionapos': 1, 'helicopter': 1, 'Tijuana': 1, 'dead': 1, 'auditor': 1, 'top': 1, 'aides': 1, 'UC': 1, 'President': 1, 'Napolitano': 1, 'interfered': 1, 'audit': 1, 'recommends': 1, 'reforms': 1, 'EDITION': 1, 'Local': 1, 'Sports': 1, 'Popular': 1, 'Ad': 1, '74deg': 1}\n"
     ]
    }
   ],
   "source": [
    "f = request.urlopen('http://www.latimes.com')\n",
    "source_bytes = f.read()\n",
    "source = source_bytes.decode('utf-8')\n",
    "with open(\"www.latimes.com.html\",'w',encoding='utf8') as f:\n",
    "    f.write(source)\n",
    "a = source\n",
    "cnt=0\n",
    "cnt\n",
    "list = []\n",
    "\n",
    "\n",
    "while(cnt != len(a)) :\n",
    "    \n",
    "        if a[cnt] == '<' :\n",
    "            if(a[cnt+1] == '!' and a[cnt+2]=='-') : #주석 삭제\n",
    "                cnt+=3\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt] == '-' and a[cnt+1] == '>'):\n",
    "                        cnt+=1\n",
    "                        break\n",
    "            elif(a[cnt+1:cnt+7] == \"script\" ) : #스크립트 삭제\n",
    "                cnt+=7\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+8] == \"/script>\"):\n",
    "                        cnt+=8\n",
    "                        break\n",
    "                        \n",
    "            elif(a[cnt+1:cnt+6]) == \"style\" : ##css 삭제\n",
    "                cnt+=6\n",
    "                while True:\n",
    "                    cnt+=1\n",
    "                    if(a[cnt:cnt+6]) == '/style':\n",
    "                        cnt+=6\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    \n",
    "            else:\n",
    "                while(a[cnt] != '>'): #HTML 삭제\n",
    "                    cnt+=1\n",
    "                    \n",
    "        \n",
    "        elif  a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt]!=' ' and a[cnt] !='\\n' :\n",
    "            start = cnt\n",
    "            while a[cnt] != '<' and a[cnt] != '>' and a[cnt]!='\\t' and a[cnt] !=' ' and a[cnt] !='\\n' :\n",
    "                    cnt+=1\n",
    "                    if(cnt==len(a)):\n",
    "                            break\n",
    "                        \n",
    "            end = cnt\n",
    "            list.append(a[start:end])\n",
    "            \n",
    "        else :\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "c=[]\n",
    "for x in string.punctuation: #구두문자 리스트화\n",
    "    c.append(x)\n",
    "c.append(\"\\r\")\n",
    "c.append(\"nbsp\")\n",
    "c.append(\"raquo\")\n",
    "\n",
    "for x in range(len(list)) : #구두문자가 list의 원소안에 포함되어있을 경우\n",
    "    for k in c:\n",
    "        if k in list[x]:\n",
    "            list[x] = list[x].replace(k,'') #구두문자를 없앤다\n",
    "    \n",
    "\n",
    "list.remove('') #구두문자만 있었을 경우 공백만 남으므로 공백 없애줌\n",
    "            \n",
    "dic = dict()\n",
    "for x in list:\n",
    "    if x not in dic.keys(): #list의 원소가 사전에 없으면 추가\n",
    "        dic[x] = 1\n",
    "    elif x in dic.keys(): #이미 있는 원소면 1추가\n",
    "        dic[x] += 1\n",
    "        \n",
    "f = open(\"StopwordList.txt\",\"r\")\n",
    "stopword = f.readlines()\n",
    "stopword_title = []\n",
    "for i in range(len(stopword)):\n",
    "    stopword[i] = stopword[i][:-1]\n",
    "for i in range(len(stopword)):\n",
    "    stopword_title.append(stopword[i].title())\n",
    "\n",
    "dict_key_list = []\n",
    "for i in dic.keys():\n",
    "    dict_key_list.append(i)\n",
    "for ele in stopword :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "for ele in stopword_title :\n",
    "    if ele in dic.keys():\n",
    "        del dic[ele]\n",
    "while '' in dic.keys():\n",
    "    del dic['']\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key = lambda x : x[1], reverse = True)\n",
    "url_frequency = \"www.latimes.com.words.frequency\"\n",
    "with open(url_frequency,\"wb\") as f:\n",
    "    pickle.dump(dict(dic_sorted), f)\n",
    "    \n",
    "with open(url_frequency,\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. StopwordList,txt라는 파일을 따로 만든다. 파일에는 모든 Stopword가 라인단위로 저장되어있다.\n",
    "2. StopwordList.txt를 \"r\"모드로 읽을수있게 f파일객체를 만들고 readlines() 메소드로 모든라인의 stopword를 stopword리스트에 저장한다. readlines()로 불러온 각 단어들은 끝에 \\n가 붙어있으므로 인덱싱과 슬라이싱을 이용해 제외시킨 후 다시저장한다.\n",
    "3. 모든 소문자와 첫글자가 대문자(예를들어 with, With)은 같은 stopword이고 제외되야 할 대상이므로 stopword_title 리스트에는  각 문자열의 title() 형식이 저장된다.\n",
    "4. dict_key_list는 전 과제에서 구했던 사전의 key값들을 저장하는 리스트이다. 모든 key값을 저장 후 stopword와 stopword_title에 있는 원소들이 keylist에 있으면 del을 이용해 제외시켜준다. 이로써 모든 stopword가 사전에서 제외된다.\n",
    "5. 빈 원소 ('') 들도 while문을 이용하여 모두 없애준다.\n",
    "6. 이후 sorted함수를 통해 key값을 value값으로 설정. 이는 lambda함수를 이용( dic.items()의 원소들을 인자로 주고, 첫번째 인덱스(x[1] => value)를 반환.) reverse값은 True로 설정해 내림차순으로 정렬한 후 dic_sorted에 저장한다.\n",
    "7. 마지막으로 pickle 모듈을이용해 dic_sorted를 pickling한다. dic_sorted는 dic_items() 형식이므로 이를 사전형으로 형변환 후 dump시켜준다. 저장되는 파일명의 형태는 URL.words.frequency 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "http://www.nytimes.com\n",
      "{'Thanksgiving': 15, 'Times': 14, 'York': 12}\n",
      "\n",
      "\n",
      "http://www.nytimes.com\n",
      "{'US': 14, 'CNN': 11, 'International': 11}\n",
      "\n",
      "\n",
      "http://www.nytimes.com\n",
      "{'US': 37, 'News': 31, 'Thanksgiving': 29}\n",
      "\n",
      "\n",
      "http://www.nytimes.com\n",
      "{'Houston': 28, 'Black': 26, 'Friday': 26}\n",
      "\n",
      "\n",
      "http://www.nytimes.com\n",
      "{'32': 36, 'Thanksgiving': 13, 'LA': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "urls = [url, url2, url3, url4, url5]\n",
    "urls_frequencies = []\n",
    "for i in range(len(urls)):\n",
    "    urls_frequencies.append(urls[i][7:] + \".words.frequency\")\n",
    "for ele in urls_frequencies:\n",
    "    with open(ele,\"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "    cnt =0\n",
    "    print()\n",
    "    print(url)\n",
    "    url_ele = {}\n",
    "    for i,j in x.items() :\n",
    "        url_ele[i] = j\n",
    "        cnt+=1\n",
    "        if(cnt>2):\n",
    "            break\n",
    "    print(url_ele)\n",
    "        \n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 각각의 url를 원소로 가지고있는 urls리스트를 설정한다.\n",
    "2. urls_frequencies 리스트는 각 사이트 결과를 picking 한 것에 대한 pickle 파일을 불러오기위한 이름이 저장된다.\n",
    "3. 각각의 pickling된 파일들을 for문을 이용해 하나씩 접근하고 cnt를 이용해 위에서부터 3개의 사전 원소들만 불러온다. 사전은 시퀀스형태가 아니기때문에 인덱스로 접근이 불가하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word :trump\n",
      "\n",
      "Similarity Priority\n",
      "1 st :  http://www.foxnews.com ( 16 )\n",
      "2 st :  http://www.nytimes.com ( 8 )\n",
      "3 st :  http://edition.cnn.com ( 8 )\n",
      "4 st :  http://www.chron.com ( 6 )\n",
      "5 st :  http://www.latimes.com ( 4 )\n"
     ]
    }
   ],
   "source": [
    "similarity = {}\n",
    "index_cnt = 0\n",
    "search_text_lower = {}\n",
    "\n",
    "word = input(\"input word :\")\n",
    "for ele in urls_frequencies:\n",
    "    with open(ele,\"rb\") as f:\n",
    "        search_text_original = pickle.load(f)\n",
    "        for i in search_text_original :\n",
    "            search_text_lower[i.lower()] = search_text_original[i]\n",
    "            \n",
    "        if word.lower() in search_text_lower.keys() : \n",
    "            similarity[urls[index_cnt]] = search_text_lower[word.lower()]\n",
    "        else :\n",
    "            similarity[urls[index_cnt]] = 0\n",
    "        index_cnt+=1\n",
    "        \n",
    "dic_sorted2 = sorted(similarity.items(), key = lambda x : x[1], reverse = True)\n",
    "print()\n",
    "print(\"Similarity Priority\")\n",
    "cnt =1;\n",
    "for i,j in dict(dic_sorted2).items():\n",
    "    print(cnt, \"st : \", i,'(',j,')')\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제에서 가장 중요하게 생각한 것은, 만약 soccer라는 단어를 입력했을 때, 사이트 1에서는 soccer를 4개, Soccer를 1개 가지고 있고, 사이트 2에서는 soccer를 1개, Soccer를 10개 가지고 있다고 하면, 대소문자 구별하여 soccer라는 단어만 놓고 봤을때는 사이트 1이 더 많다. 하지만 soccer나 Soccer 혹은 soCCer 등은 대소문자의 차이지 같은 의미를 가진 단어이기 때문에 이를 모두 같다고 봐야한다고 생각했다. 즉 soccer라는 단어를 사이트 1은 5개, 사이트 2는 11개를 가지고 있는 것이다.\n",
    "\n",
    "1. similarity는 각 사이트들이 가지고있는 유사도값을 높은순서대로 가질 사전객체이다.\n",
    "2. index_cnt는 urls 리스트(각 사이트들의 주소를 원소로 가지는)에 대한 index이다.\n",
    "3. search_text_lower은 사이트들의 모든 순수 단어들에 대한 출현횟수를 가지고있는 사전객체에서 모든 원소들에 대한 key값을 lower()메소드를 이용해 소문자로 바꿔진 사전원소들을 가진다.\n",
    "4. search_text_original에 각 사이트들에 대한 frequency pickle 파일에 저장된 사전객체를 저장한다.\n",
    "5. for문과 lower()메소드를 이용해 search_text_original에 저장된 모든 key값이 lower()로 바뀐 사전원소들을 저장한다. (3번내용)\n",
    "6. 입력받은 단어(word).lower() 가 seatch_text_lower.keys()에 있다면 similarity[url]의 value 값은 해당 단어의 출현 횟수이다.  \n",
    "=> ex) trump를 입력받았고 CNN 사이트에 trump라는 단어가 8개 있다면 similarity에서 {'http://edition.cnn.com': 8} 이 된다.\n",
    "7. 이것들을 내림차순으로 정렬시킨 결과를 dic_sorted2에 저장 후 알맞게 출력시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상업적인 완성도 높은 검색 로봇/엔진이 되기위해 추가되야할 기능 3가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\n",
    "\n",
    "찾고자 하는 단어를 완전히 완성시키지 않아도 미완성된 단어로 만들수있는 모든 경우의수를 나타내주는 기능.  \n",
    "물론 이는 사람들이 많이 검색한 순, 즉 선호도를 바탕으로 나타나야한다. 예를들어 '즐라탄 이브라히모비치' 라는 축구선수에 대해 알고싶어서 검색한다고 했을 때, 저 긴 이름을 매번 일일히 타이핑한다는 것은 비효율적이다. 또한 갑자기 '즐라..' 까지밖에 기억이 안나면 검색하고싶어도 할 수 없는 노릇이다. 다만 이러한 기능이 있다면 '즐라' 정도까지만 쳐도 '즐라탄 이브라히모비치' 는 물론이거니와 '즐라탄 이브라히모비치 이적' '즐라탄 이브라히모비치 자서전' 등과같이 찾고자하는 것과 관련있는 정보도 함께 보여주며 검색할 수 있게된다.\n",
    "\n",
    "\n",
    "-\n",
    "\n",
    "불필요한 내용을 걸러주는 기능. 사실 어떠한 정보를 얻기위해 해당 정보의 키워드를 검색한다고 해서 정확히 그것과 관련있는 내용들만 추출하기는 어렵다. 물론 해당 정보에 대해 구체적이고 자세히 검색한다면 정확도는 그만큼 높아지겠지만, 그렇지 않고 모호한 정보로 검색하는 경우가 많다. 따라서 키워드를 입력받고 그에 해당되는 내용과 '거의' 관련이 없다고 보이는 내용들의 우선순위를 최대한 낮추는 기능이 필요하다.  \n",
    "\n",
    "-\n",
    "\n",
    "단순히 해당 단어에 대해서만 검색하는것이 아닌, 사용자의 심리(의도)까지 파악하여 정보를 불러오는 기능.  \n",
    "최근에 이러한 기능에 대한 재미있는 예를 봤는데, 네이버 이미지에 '길거리' 를 검색해보면 말그대로 '길거리들'만 엄청나게 나온다. 반면에 구글에서 이미지로 검색할 경우, '길거리' 음식들, 혹은 압도적으로 높은 비율로 '길거리'에있는 '여성'(?)들의 사진 등이 나온다. 이는 구글이 '길거리' 라는 단어를 단어 자체만으로 보지 않고 '길거리'라고 검색했을 사용자의 심리를 꿰뚫고 그에 걸맞는 이미지를 불러온 것이 아닐까 하는 생각이다. 이처럼 단순히 해당 단어 자체만으로 자료를 찾는것이 아닌 사용자의 심리를 어느정도 파악하여 왜 이러한 검색을 했을지를 유추하고 그에 맞는 정보를 제공할 수 있는것이 수준높은 검색엔진의 토대라고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 느낀점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 교수님이 이번과제의 기간을 평소보다 길게내주셨는지를 알 것 같습니다. 확실히 전에했던 과제들에 비해 시간이 많이 걸렸습니다. 모든 문제를 다 작성하고나서의 뿌듯함도 잠시 이렇게 별거없는 기능들을 구현하는 데에도 상당히 오랜시간이 걸렸다는것에 부족함을 많이 느꼈습니다. 내가 정말 사람들이 나서서 써줄만한 프로그램을 만들기까지의 과정이 결코 만만하거나 쉽지 않다는 것을 학기중에 내주신 과제들을 할때마다 많이 느낍니다. 더욱 열심히 노력하겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
